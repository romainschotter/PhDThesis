%//------ Section 03 -------------------------------------------------------------------------------------------------
\chapter{Mass measurements of multi-strange baryons in pp collisions at \sqrtS = 13 TeV}
\label{chap:CPTAnalysis}
%//-----------------------------------------------------------------------//

The first analysis conducted in this thesis aims at measuring the \rmXiM, \rmAxiP, \rmOmegaM, \rmAomegaP masses and mass differences between particle and anti-particle. This chapter provides a description of the different elements needed for its achievement. 


\section{Introduction}

%Symmetries certainly stand as one of the most fruitful concepts in Physics. They are of two kinds: continuous --- such as the global translations in both space and time, or the Lorentz transformations --- and discrete --- for example, the space- (P) and time- (T) inversions, the charge conjugation (C), and their combined transformation given by CPT. In particular, the Lorentz and CPT symmetries are connected by the so-called CPT theorem which states that any local Lorentz-invariant quantum field theory must also (under some extra requirements) be CPT invariant \cite{cptstatus}. Consequently, the CPT violation implies the breaking of the Lorentz symmetry, and vice versa\footnote{In fact, there is another option; to allow for CPT to be violated, either the Lorentz symmetry must be broken -- as in the string theory \cite{string} or the Standard-Model Extension \cite{sme} -- or some of the other extra assumptions of the CPT theorem must be dropped, namely the energy positivity, local interactions, finite spin, etc \cite{cptimplieslorentz}\cite{cptsymmetryantitsviolation}. } \cite{sozzi}. Another implication involves the relation between the properties of matter and antimatter: due to the charge conjugation linking particles to antiparticles, the CPT symmetry imposes that they share the same invariant mass, energy spectra, lifetime, coupling constants, etc \cite{cptsymmetryantitsviolation}. Most of the experimental checks of CPT invariance stem from these physical consequences.

As discussed in \Sec\ref{subsec:Theory}, the Standard Model is built upon a set of symmetries, each being either discrete -- such as the combination of the charge conjugation (C), parity (P) and time reversal (T), known as the CPT transformation -- or continuous -- for example, the Lorentz transformations that includes rotations and boosts. In particular, the Lorentz and CPT symmetries are connected by the so-called CPT theorem which establishes that any unitary, local Lorentz-invariant quantum field theory must be CPT invariant \cite{kosteleckyStatusCPT1998}. Consequently, the CPT violation implies the breaking of the Lorentz symmetry, and vice versa\footnote{In fact, another option exists; to allow for the CPT violation, either the Lorentz symmetry must be broken -- as in the case of string theory \cite{kosteleckySpontaneousBreakingLorentz1989} or the Standard-Model Extension \cite{colladayLorentzviolatingExtensionStandard1998} -- or some of the other additionnal assumptions of the CPT theorem must be dropped, namely the energy positivity \cite{abersDiseasesInfiniteComponentField1967}, local interactions \cite{carruthersIsospinSymmetryTCP1968}, finite spin \cite{oksakInvalidityTCPtheoremInfinitecomponent1968}, etc \cite{greenbergCPTViolationImplies2002}\cite{lehnertCPTSymmetryIts2016}. } \cite{sozziTestsDiscreteSymmetries2019}. Another implication involves the relation between the properties of matter and antimatter: due to the charge conjugation linking particles to antiparticles, the CPT symmetry imposes that they share the same invariant mass, energy spectra, lifetime, coupling constants, etc \cite{cptsymmetryantitsviolation}. Most of the experimental checks of CPT invariance stem from this last point, which imposes several constraints on the anti-particle properties. \\

The Particle Data Group (PDG) \cite{particledatagroupReviewParticlePhysics2022} compiles a large variety of CPT tests from many experiments and with different degrees of precision; so far, no CPT violation have been observed. The most stringent test involves the \rmKzero-\rmAKzero mixing process, which depends on the mass and lifetime differences of these two states. In this way, assuming no other source of CPT violation in the decay of neutral kaons, these two quantities have been bounded \cite{particledatagroupReviewParticlePhysics2022}\cite{angelopoulosK0K0Mass1999} to 

\begin{equation}
2 \frac{\mid m_{\rmKzero} - m_{\rmAKzero} \mid}{m_{\rmKzero} + m_{\rmAKzero}} < 6 \times 10^{-19} \quad , \quad 2 \frac{\mid \Gamma_{\rmKzero} - \Gamma_{\rmAKzero} \mid}{\Gamma_{\rmKzero} + \Gamma_{\rmAKzero}} = (8 \pm 8) \times 10^{-18}.
\end{equation}

These indirect limits are much stronger than the ones extracted from direct tests. For example, in the hyperon sector, the precision on relative mass difference is typically of a few $10^{-5}$. In the latter case, it should be mentioned that there is still some room for improvements, and most particularly concerning the mass difference measurements between particle and anti-particle in the multi-strange baryon sector. The only test of this nature dates back to 2006 \cite{abdallahMassesLifetimesProduction2006} for the \rmXiM and \rmAxiP, and from 1998 \cite{chanMeasurementPropertiesOverline1998} for the \rmOmegaM and \rmAomegaP. The former was achieved by exploiting 3.25 million hadronic decays of the \rmZzero recorded by the DELPHI detector at LEP-1; the latter was obtained on the E756 spectrometer at Fermilab, using an 800 \gmom proton beam on a beryllium target. However, both studies suffer from low statistics: approximately 2500(2300) reconstructed \rmXiM (\rmAxiP) and about 6323(2607) reconstructed \rmOmegaM (\rmAomegaP) were used.\\

\begin{table}[t]
    \centering
    \begin{tabular}{>{\centering\arraybackslash}b{1.5cm}@{\hspace{0.3cm}} >{\centering\arraybackslash}b{1.75cm}@{\hspace{0.3cm}} >{\centering\arraybackslash}b{2.85cm}@{\hspace{0.3cm}} >{\centering\arraybackslash}b{3.6cm}@{\hspace{0.3cm}} >{\centering\arraybackslash}b{2.5cm}@{\hspace{0.3cm}} >{\centering\arraybackslash}b{1cm}@{\hspace{0.3cm}}}
    \noalign{\smallskip}\hline\noalign{\smallskip}
	Particle & Quark content & Mass (\mmass) & Relative mass difference & Dominant decay channel & B.R.\\	
    \noalign{\smallskip}\hline \noalign{\smallskip}
    	
	\rmKzeroS (\rmAKzeroS) & $d \bar{s}$ ($\bar{d} s$)& $497.611 \pm 0.013$ & $< 6 \times 10^{-19}$ & \piPlus \piMinus & 69.20\%\\
	
    \noalign{\smallskip}\hline \noalign{\smallskip}
    
    \rmLambda (\rmAlambda) & $u d s$ ($\bar{u}\bar{d}\bar{s}$) & $1115.683 \pm 0.006$ & $\left(-0.1 \pm 1.1\right) \times 10^{-5}$ & \proton \piMinus (\pbar \piPlus) & 63.9\% \\
    
    \noalign{\smallskip}\hline \noalign{\smallskip}    
    
    \rmXiM (\rmAxiP) & $dss$ ($\bar{d}\bar{s}\bar{s}$) & $1321.71 \pm 0.07$ & $\left(-2.5 \pm 8.7\right) \times 10^{-5}$ & \rmLambda \piMinus (\rmAlambda \piPlus) & 99.9\% \\	
    \noalign{\smallskip}\hline \noalign{\smallskip}
    
	\rmOmegaM (\rmAomegaP) & $sss$ ($\bar{s}\bar{s}\bar{s}$) & $1672.45 \pm 0.23$ & $\left(-1.44 \pm 7.98\right) \times 10^{-5}$ & \rmLambda \rmKminus (\rmAlambda \rmKplus) & 67.8\%\\    
    \noalign{\smallskip}\hline\noalign{\smallskip}
    \end{tabular}
    \caption{A few characteristics, as of 2023, of the \rmLambda, \rmXi, \rmOmega hyperons and the \rmKzeroS meson: quark content, mass, relative mass difference values with their associated uncertainties and their dominant decay channel as well as the corresponding branching ratio \cite{particledatagroupReviewParticlePhysics2022}.}\label{tab:V0CascPDGMass}
\end{table}

In comparison, all the pp collisions at a centre-of-mass energy of 13 \tev collected by ALICE throughout the LHC Run-2 contains about 2 400 000 \rmXi and 129 000 \rmOmega, with little background. Therefore, in this thesis, the measurement of the mass difference of \rmXiM and \rmAxiP, and \rmOmegaM and \rmAomegaP hyperons is performed. It relies on data samples much larger than those exploited previously. These direct measurements of the mass difference offer a test of the CPT invariance to an unprecedented level of precision in the multi-strange baryon sector. The absolute masses are updated as well, with a precision substantially better than the current values listed in the PDG and presented in the \tab\ref{tab:V0CascDecay}.

Furthermore, concerning the \rmLambda hyperon and \rmKzeroS meson, the PDG quotes a precision of a few \kmass on the mass value, and about $1 \times 10^{-5}$ on the relative mass difference value\footnote{This only concerns the relative mass difference between \rmLambda and \rmAlambda. As mentioned above, such quantity is much smaller by fourteen orders of magnitude in the case of \rmKzero.}. Abundantly produced, these two hadrons also exhibit an irresistible feature in the context of this thesis: both decay into a V0 in their dominant decay channel, and so can be identified in a similar manner as cascades using topological reconstruction. For those two reasons -- high precision on the PDG mass values, and similar decay topology as cascade --, the analysis is reproduced on \rmLambda and \rmKzeroS, both being used as a benchmark for the measurement.\\

In the following, the term \textit{mass difference} always refers to the relative one, namely $2 \left(\mMassPart{part.} - \mMassApart{part.} \right)/\left(\mMassPart{part.} + \mMassApart{part.}\right)$, unless indicated otherwise.

\section{Data samples and event selection}

\subsection{The data samples}
\label{subsec:DataSamples}

All the data samples employed for this measurement originates from the second campaign of data taking, the LHC Run-2. The latter comprises different collision systems at various energies, mainly pp collisions at \sqrtS = 13 \tev and Pb-Pb collisions at \sqrtSnn = 5.02 \tev. Based on the elements in \Sec\ref{subsec:HyperonAndALICE}, the analysis exploits the former ones as they provide a less dense collision environment, expectedly easier to reconstruct and thus more controllable. All these pp events have been collected during three data taking periods: between April and October 2016, May and November 2017, April and October 2018 (\Sec\ref{subsec:acceleratorprogramme}, \tab\ref{tab:LHCRunProgramm}).

Considering the target precision on the mass and mass difference values, it is crucial to have a fine comprehension of the data reconstruction to keep it well under control. For that reason, the analysis uses data in ESD format as they contain all the informations related to event building, thus offering the possibility to replay \textit{offline} the V0 and cascade vertexings/formations. As mentioned in \Sec\ref{subsubsec:DataFormats}, the first full reconstruction cycle (\Sec\ref{subsubsec:computingmodel}), performed right after their recording of the data, produces ESD files labelled as \textit{pass-1}. Since then, other reconstruction cycles have been carried out, each iteration bringing its share of improvements or fixes. The events analysed for this measurement originates from the second reconstruction cycle, the pass-2, which offers better tracking performances: same version of analysis software over all the data taking periods leading to more uniform performances, better SPD and TPC alignments, improved TPC reconstruction and finer description of the distortions within the TPC gas.

Each period consists in fact of dozens or hundreds of \textit{runs}, corresponding to sequences of events recorded in an uninterrupted manner\footnote{Throughout the data taking, it is more or less frequent to interrupt the data collection, \ie stop the run. This usually occurs when a detector encounters an error, unfixable while collecting data. Broadly speaking, a period regroups a set of runs that have been recorded within the same data taking conditions.}. The lists of approriated runs for physics analysis are defined by the ALICE Data Preparation Group (DPG). As its name suggests, the latter oversees the preparation, reconstruction, quality assurance of both collected and simulated data, as well as the upkeep of the analysis tools including the event and track selections \cite{alicecollaborationALICEDataPreparation2023}. The list of runs employed in this study follows the DPG's one for an analysis using central barrel detectors and requiring hadron PID. For a run to be in that list, all the detectors related to the tracking and PID must be operational -- \ie SPD, SDD, SSD (ITS), TPC, TOF --, as well as those in charge of triggering, that are the V0 and T0. Note that it does not mean that the PID performances are optimal, nor that the full acceptance of each detector is covered.\\

Besides the real data sample, the measurement also relies on simulated data in order to estimate and optimize the performances of the analysis. To each run corresponds its simulated counterpart, anchored on pass-2 data, as described in \Sec\ref{subsubsec:MCData}. All the exploited MC productions employ \Pythiaeight (version 8.2, tune: Monash 2013) as event generator. For the transport and interaction with the material of the ALICE detector, most of them use \GeantThree; although \GeantFour runs faster, describes more accurately hadronic interactions at very low momentum and is better maintained, only a few of the exploited simulations rely on it \cite{barendsGeant4ValidationStudy2017}.

Since both abundant (\rmKzeroS, \rmLambda and to a certain extent, \rmXi) and rare species (\rmXi and \rmOmega) are being studied, one may resort to two kinds of simulations: general-purpose MC productions for the first ones, and enriched MC productions for the others. Here, the enriched simulations have been obtained by selecting the events that includes, at least, a \rmKzeroS, \rmLambdaPM, \rmXiPM or \rmOmegaPM in $\abspseudorap < 1.2$.

Furthermore, this analysis also makes use of the track references in the simulation. As mentioned in \Sec\ref{subsubsec:MCData}, these correspond to the MC informations of the considered track at the location where it crosses a given detection plane. Thereby, they allow to compare the reconstructed track informations with the actual/generated ones at any point along the particle trajectory\footnote{Strictly speaking, this comparison cannot be done at any point since the track reference is only available where the particle traverses a sensitive volume.}. Although the track references are effectively stored for only 10\% of the production\footnote{This is done in order to spare some disk space.}, this comparison is proving invaluable to control the tracking in ALICE.\\


In total, the exploited data sample counts about 2.6 billions minimum bias events at \sqrtS = 13 \tev, and approximately 600 millions events in the associated MC productions.

\subsection{The event selection}
\label{subsec:EventSelection}

As mentioned in \Sec\ref{subsec:TriggerSystem}, the analysis focuses on minimum-bias and/or high-multiplicity events. More precisely, the respective trigger configurations correspond to the MB$_{\rm AND}$ and/or HM$_{\rm VZERO}$. Not all the events passing these trigger selections are considered; additional cuts are applied in order to filter out only those of \say{good} quality for a physics analysis. \\

During the data acquisition (DAQ), the event-builder proceeds to the event reconstruction based on the sub-events from all contributing detectors. It may happen, however, that the detector's output can not be transmitted due to the associated data channel being closed\footnote{There are different reasons for the data channel to be closed. At the beginning or the end of each run, a specific procedure is performed on all detectors in order to effectively initiate the start or stop of the run. In particular, the \say{End Of Run} procedure has to close all the data channel connecting the event-builder and the sub-detectors -- \ie the GDCs and LDCs respectively (\Sec\ref{subsec:TriggerSystem}) --, but this termination can occur sooner in the case of a connection time-out for example.} \cite{alicecollaborationTriggerDataAcquisition}. The event-builder still reconstructs the event, although it is tagged as \say{incomplete DAQ} due to the missing informations. Such events are rejected in the present work.\\

There exists three types of reconstructed primary vertex in ALICE, from the highest to the poorest quality: one estimated using the global ITS-TPC tracks (\Sec\ref{subsubsec:FinalVertexDet}), another based on the SPD tracklets (\Sec\ref{subsubsec:PreliminaryVertex}), and the last built from the TPC standalone tracks in a similar way as the former. By default, only the \say{best} available reconstructed primary vertex is considered. 

Nevertheless, to ensure that the event has a vertex of a sufficiently good quality, the analysis relies exclusively on the first two aforementioned primary vertices. This boils down to requiring the presence of, at least, the one reconstructed using tracklets\footnote{As mentioned in \Sec\ref{subsubsec:PreliminaryVertex}, the event cannot be built without the primary vertex based on SPD tracklets. Hence, by construction, the presence of such vertex is guaranteed in the event.}. Moreover, the resolution of the latter in the longitudinal direction should not exceed 0.25 \cm. In cases when both SPD tracklets and global ITS-TPC track vertices are available, their positions along the beam axis must coincide within a 0.5 \cm window.

As a prerequisite for guaranteeing an uniform reconstruction efficiency, particles must remain within the acceptance of all the central detectors involved in their reconstruction, that is $\abspseudorap < 0.9$. For particles originating from the interaction point, this condition implies a constraint on the longitudinal position of the primary vertex: the distance between the interaction point and the centre of ALICE should be below 10 \cm along the beam axis\footnote{Note that there is no selection of such nature concerning the transverse position of the primary vertex, except that it must be located below the beam pipe.}. \\

A key element of the event quality concerns the pile-up level. The latter occurs when there are two or more collisions coming from the same bunch crossing -- this is the \textit{in-bunch} pile-up -- and/or from different bunch crossings occuring within the readout time of the detectors -- also called \textit{out-of-bunch} pile-up. One approach to remove both types of pile-up consists in rejecting events with multiple reconstructed primary vertices. This selection depends on the nature of the best primary vertex available.
\begin{itemize}
\item[$\bullet$] If it is the one reconstructed using ITS-TPC tracks, the event selection algorithm checks the presence of another vertex of reasonably good quality ($\rmChiSquareNDF < 5$, with $NDF$ the number of degree of freedom), formed out of at least five tracks, and separated from the first one by more than $15 \sigma$\footnote{Here, $\sigma$ denotes the uncertainty on the distance between the two vertices.}. If such vertex exists, the event is discarded. 
\item[$\bullet$] Otherwise, it corresponds to the one built from SPD tracklets. To maximise the selection efficiency, the cuts adapt to the tracklet multiplicity. Hence, if a second vertex is found to be away from the first one by more than 0.8 \cm along the beam axis, with at least three, four or five associated tracklets for a total number of reconstructed tracklets (\rmNTracklet) inferior to 20, $20 < \rmNTracklet \leq 50 $ and \rmNTracklet > 50 respectively, then the event is rejected.
\end{itemize}


Along the same line, the two innermost layers of the ITS can help to identify the remaining beam-induced background -- that have not been removed by the MB$_{\rm AND}$ trigger selection -- and pile-up events. As mentioned in \ref{subsubsec:PreliminaryVertex}, a tracklet is formed out of pair of clusters found in the two SPD layers, separated by an angle of 0.01 rad at most. Therefore, the number of clusters increases, so does the amount of reconstructed tracklet. However, in the case of beam-gas event, there should be many clusters but only a small number of tracklets could be formed using the previous definition. In pile-up events, only the tracklets associated with the primary vertex are considered; for that reason, the number of clusters should be relatively larger than expected at such tracklet multiplicity \cite{alicecollaborationALICEPhysicsForum2016}. In this way, based on this correlation between the number of SPD clusters and tracklets, the remaining events flagged as background or pile-up are rejected. \\

\begin{figure}[t]
	\centering
	\includegraphics[width=1\textwidth]{Figs/Chapter5/EventSelection.eps}
	\caption{Fraction of rejected events in the present data sample for each event selection: trigger selections (MB$_{\rm AND}$ and/or HM$_{\rm VZERO}$), incomplete DAQ, consistency between the global track and SPD tracklet vertices, longitudinal position of the primary vertex ($\mid \Delta z \mid < 10 $ \cm), pile-up removal for ITS-TPC track and SPD tracklet vertices, correlation between SPD tracklets and clusters.}
	\label{fig:EvtSelection}
\end{figure}


The \fig\ref{fig:EvtSelection} provides the fraction of rejected events as a function of the above selections in pp collisions at \sqrtS = 13 \tev.

\section{Analysis of the hyperon masses}

\subsection{Track selections}
\label{subsec:TrackSelections}

The identification of V0s and cascades strongly depends on the quality of the daughter tracks, and more precisely on their momentum resolution and trajectory. For that reason, the strange particle reconstruction relies exclusively on ITS-TPC combined tracks, since they offer the best momentum resolution as discussed in \Sec\ref{subsubsec:TrackReco} and shown in \fig\ref{fig:MomResolution}. In order to ensure an excellent momentum resolution as well as a fine estimation of the particle trajectory, various selection criteria are applied on the daughter tracks.\\

The analysis concentrates exclusively on tracks comprised within the pseudo-rapidity region $\abspseudorap < 0.8$. The latter corresponds to the acceptance volume of all the central detectors, which provides a flat reconstruction efficiency. Moreover, any track containing ITS and/or TPC shared clusters is rejected, as they potentially correspond to wrongly assigned clusters that could bias the tracking quality. 

Tracks belonging to a \textit{kink} vertex are discarded from the analysis, as they most certainly do not originate from a cascade decay and thus represent an additional source of combinatorial background. A kink usually happens when a charged particle decays into a neutral and a charged particle, such as $\Kplusmin \rightarrow \piZero \rmPiPM$. The former being undetected, they are identified by forming pairs of tracks, that intersect in space with a large angle and share the same electric charge.

Each track should have passed the final refit in the TPC. This means that its parameters have been estimated successfully in the TPC during the third stage of the tracking, when the track is propagated inwards to their distance of closest approach to the primary vertex (\Sec\ref{subsubsec:TrackReco}). To guarantee a good momentum resolution and a stable particle identification (PID) based on the energy deposit (\dEdx) in the TPC, the tracks need to be associated to at least 70 readout pad rows in the TPC out of 159 in total. These selections eliminate the contribution of short tracks and, incidentally, pairs of tracks formed out of the clusters from a single actual particle.\\

The reconstruction of V0s and cascades presented in \chap\ref{chap:V0CascReconstruction} does not resort to any kind of selections on the nature of the daughter particles, apart from their electric charge. This yields \textit{de facto} to an outstanding amount of background candidates. One way of suppressing the latter with a minimal cost in terms of signal candidates consists in using the PID informations provided by the TPC. In practice, the idea is to reject every association that involves tracks inconsistent with the expected identities for either a \rmKzeroS, \rmLambdaPM, \rmXiPM or \rmOmegaPM decay.

As explained in \Sec\ref{subsubsec:TPC}, a track can be labeled as a pion, proton or kaon by making use the PID estimator in \eq\ref{eq:PIDEstimator}, \Nsigma, which evaluates the difference between the measured \dEdx and the expected one under a given particle mass hypothesis in units of relative resolution. The separation power of such estimator evolves with the particle momentum which, in turn, influences the selection threshold and has some implications in terms of purity and efficiency: the tighter the selection on \Nsigma, the higher the purity but at the price of a small efficiency; conversely, a looser cut on \Nsigma deteriorates the purity in favour of a higher efficiency.

The identification strategy adopted here consists in selecting only the tracks compatible with their expected mass hypothesis within \Nsigma = $\pm 3$ at most. This selection is applied on each decay daughters, irrespective of their momentum or the one of the mother particle. This therefore imposes that:
\begin{itemize}
\item[$\bullet$] the bachelor track must consistent with the \rmPiPM or \rmKPM mass hypothesis, in the case of \rmXiPM or \rmOmegaPM respectively,
\item[$\bullet$] the positive track needs to be compatible with a proton hypothesis,
\item[$\bullet$] and the negative track has to agree with energy loss band of the pion.
\end{itemize}
Note that the last two constraints only allow to identify a \rmLambda and, associated with the bachelor track, a \rmXiM or \rmOmegaM. In order to select their anti-particle, one needs to swap the mass hypothesis of these two items, namely the positive track corresponds to a pion and the negative track, an anti-proton. For the \rmKzeroS, the particle is indistinguishable from the anti-particle in exploited V0 decay channel; both positive and negative tracks should be compatible with the pion hypthesis.


\subsection{V0s and cascades selections}
\label{subsec:V0CascSelections}

\subsubsection{Topological and kinematic selections}

Once the events and tracks have been selected, the topological reconstruction of V0s and cascades comes into play, as explained in \chap\ref{chap:V0CascReconstruction}. However, not all the candidates are considered in the analysis. As suggested in \Sec\ref{subsec:HyperonAndALICE}, ALICE is well suited for studying hyperons but only at mid-rapidity. This means that the V0s and cascades are reconstructed in the rapidity window $\absrap < 0.5$.

\begin{table}[t]
    \centering
    \begin{tabular}{c|c|c}
    \noalign{\smallskip}\hline \noalign{\smallskip}
    \bf Candidate variable & Selections \rmLambdaPM & Selections \rmKzeroS \\
    \noalign{\smallskip}\hline \noalign{\smallskip}    
    V0 \pT interval (\gmom) & \multicolumn{2}{c}{1 < \pT < 5} \\
    V0 rapidity interval & \multicolumn{2}{c}{\absrap < 0.5} \\
    Competing mass rejection (\gmass) & > 0.010 & > 0.005 \\
    MC association (MC only) & \multicolumn{2}{c}{Correct identity assumption} \\ 

    \noalign{\smallskip} \hline \noalign{\smallskip}
    \bf Track variable & Selections \rmLambdaPM & Selections \rmKzeroS \\
    \noalign{\smallskip} \hline \noalign{\smallskip}
    Pseudo-rapidity interval & \multicolumn{2}{c}{\abspseudorap < 0.8} \\
    TPC refit & \multicolumn{2}{c}{\CheckGr} \\
    Nbr of crossed TPC readout rows & \multicolumn{2}{c}{ > 70} \\
    $\Nsigma^{\rm TPC}$ & \multicolumn{2}{c}{< 3} \\
    \multirow{ 2}{*}{Out-of-bunch pile-up rejection} & \multicolumn{2}{c}{at least one track with} \\
     & \multicolumn{2}{c}{ITS-TOF matching} \\
    
    \noalign{\smallskip}\hline \noalign{\smallskip}
    \bf Topological variable & Selections \rmLambdaPM & Selections \rmKzeroS \\
    \noalign{\smallskip}\hline \noalign{\smallskip}
    
    V0 decay radius (\cm) & \multicolumn{2}{c}{> 0.5}\\
    V0 Lifetime (\cm) & \multicolumn{2}{c}{< 3 $\times$ \cTau}\\
    V0 cosine of pointing angle & \multicolumn{2}{c}{> 0.998}\\
    DCA proton to prim. vtx (\cm) & > 0.06 & \NoWay \\
    DCA pion to prim. vtx (\cm) & \multicolumn{2}{c}{> 0.06} \\
%    DCA V0 to prim. vtx (\cm) & < 1 & < 0.06 \\
    DCA between V0 daughters (std dev) & \multicolumn{2}{c}{< 1} \\
    
    \noalign{\smallskip}\hline \noalign{\smallskip}
    \end{tabular}
    \caption{Summary of the topological and track selections, as well as the associated cut values, used in the reconstruction of \rmLambdaPM and \rmKzeroS in pp events at \sqrtS = 13 \tev. The \textit{competing mass rejection} refers to the removal of the background contamination from other mass hypotheses (\Sec\ref{subsubsec:InvariantMassSelection}). In the \rmLambdaPM case, this consists in comparing the invariant mass under the assumption of a \rmPiPlus\rmPiMinus and PDG mass of \rmKzeroS, that is the quantity $\mid\mInv{\rm hyp.\ \rmKzeroS} - \mPDG\rmKzeroS|$. When reconstructing \rmKzeroS candidates, the selection variable becomes $\mid\mInv{\rm hyp.\ \rmLambda} - \mPDG\rmLambda|$.}\label{tab:V0Selections}
\end{table}

The above selections on the track quality in TPC exclude the possibility of studying the particles of interest at low momentum ($\pT \leq 0.6$ \gmom). At such values, the V0s and cascades decay into very low momentum tracks, that can only be reconstructed via the ITS standalone tracking. Even when these tracks reach the TPC, they form short tracks and are thus rejected (\Sec\ref{subsec:TrackSelections}). As a matter of fact, in order to secure a reasonably good momentum resolution on the decay daughters, this analysis only considers candidates from 1 to 5 \gmom. On one hand, the \eq\ref{eq:Gluckstern} indicates that the momentum resolution deteriorates at low momentum ($\pT \leq 1$ \gmom) due to their relatively \say{short} track length, \say{small} number of clusters and the dominant contribution of multiple scattering. On the other hand, at high \pT ($\pT \geq 5$ \gmom), the resolution also decreases as a consequence of less pronunced track curvature.\\

To further remove the contribution from out-of-bunch pile-up events, it is required for at least one of the daughter tracks to either have a cluster in the innermost ITS layers\footnote{Technically, it is requested to have passed the final refit in the ITS and to have a hit in one of the two SPD layers.} or match with a hit in the TOF. The former uses the fast readout time of the SPD to limit the pile-up to tracks produced in collisions within $\pm$ 300 \nsec, that is twelve bunch crossings; the latter exploits the highly precise timing information of the TOF to identify the bunch crossing from which the particle originates, with an efficiency of approximately 70 to 80\% for intermediate or high \pT particles and drops rapidly for lower momentum due to mismatches \cite{alicecollaborationALICEDPGPileup}. This selection has been thoroughly studied in the context of a strange particle production analysis \cite{alicecollaborationMultiplicityDependenceMulti2020}; it was shown that applying this ITS-TOF matching condition on at least one of the decay daughters is sufficient to eliminate most of the remaining pile-up contamination.\\

\begin{table}[t]
    \centering
    \begin{tabular}{c|c|c}
    \noalign{\smallskip}\hline \noalign{\smallskip}
    \bf Candidate variable & Selections \rmXiPM & Selections \rmOmegaPM \\
    \noalign{\smallskip}\hline \noalign{\smallskip}    
    Cascade \pT interval (\gmom) & \multicolumn{2}{c}{1 < \pT < 5} \\
    Cascade rapidity interval & \multicolumn{2}{c}{\absrap < 0.5} \\
    Competing mass rejection (\gmass) & \NoWay & > 0.008 \\
    MC association (MC only) & \multicolumn{2}{c}{Correct identity assumption} \\ 

    \noalign{\smallskip}\hline \noalign{\smallskip}
    \bf Track variable & Selections \rmXiPM & Selections \rmOmegaPM \\
    \noalign{\smallskip}\hline \noalign{\smallskip}
    Pseudo-rapidity interval & \multicolumn{2}{c}{\abspseudorap < 0.8} \\
    TPC refit & \multicolumn{2}{c}{\CheckGr} \\
    Nbr of crossed TPC readout rows & \multicolumn{2}{c}{ > 70} \\
    $\Nsigma^{\rm TPC}$ & \multicolumn{2}{c}{< 3} \\
    \multirow{ 2}{*}{Out-of-bunch pile-up rejection} & \multicolumn{2}{c}{at least one track with} \\
     & \multicolumn{2}{c}{ITS-TOF matching} \\
    
    \noalign{\smallskip}\hline \noalign{\smallskip}
    \bf Topological variable & Selections \rmXiPM & Selections \rmOmegaPM \\
    \noalign{\smallskip}\hline \noalign{\smallskip}
    
    \multicolumn{3}{l}{\textbf{V0}} \\
    V0 decay radius (\cm) & > 1.2 & > 1.1\\
    V0 cosine of pointing angle & \multicolumn{2}{c}{> 0.97}\\
    |$m$($V0$) - \mPDG\rmLambda| (\gmass) & \multicolumn{2}{c}{< 0.008} \\
    DCA proton to prim. vtx (\cm) & \multicolumn{2}{c}{> 0.03} \\
    DCA pion to prim. vtx (\cm) & \multicolumn{2}{c}{> 0.04} \\
    DCA V0 to prim. vtx (\cm) & \multicolumn{2}{c}{> 0.06} \\
    DCA between V0 daughters (std dev) & \multicolumn{2}{c}{< 1.5} \\
    \noalign{\smallskip}\hline \noalign{\smallskip}
    
    \multicolumn{3}{l}{\textbf{Cascade}} \\
    Cascade decay radius (\cm) & > 0.6 & > 0.5 \\
    Cascade Lifetime (\cm) & \multicolumn{2}{c}{< 3 $\times$ \cTau}\\
    DCA bachelor to prim. vtx (\cm) & \multicolumn{2}{c}{> 0.04} \\
    DCA between cascade daughters (std dev) & \multicolumn{2}{c}{< 1.3} \\
    Cascade cosine of pointing angle & \multicolumn{2}{c}{> 0.998} \\
    Bachelor-proton pointing angle (rad) & \multicolumn{2}{c}{> 0.04} \\
    
    \noalign{\smallskip}\hline \noalign{\smallskip}
    \end{tabular}
    \caption{Summary of the topological and track selections, as well as the associated cut values, used in the reconstruction of \rmXiPM and \rmOmegaPM in pp events at \sqrtS = 13 \tev. The \textit{competing mass rejection} refers to the removal of the background contamination from other mass hypotheses (\Sec\ref{subsubsec:InvariantMassSelection})}\label{tab:CascadeSelections}
\end{table}

In summary, the \tabs\ref{tab:V0Selections} and \ref{tab:CascadeSelections} provide a list of the track and topological selections employed in the reconstruction of V0s and cascades respectively, as well as the numerical cut values. Note the tight cut on the cosine of pointing angle of the cascade candidate; this is discussed later in \Sec\ref{subsec:MassExtraction}.

\subsubsection{Structure in the invariant mass spectrum of cascades}
\label{subsubsec:InvMassStructure}

Among the topological selections listed in \tab\ref{tab:CascadeSelections}, one of them has not been introduced and discussed in \chap\ref{chap:V0CascReconstruction}, namely the cut on the pointing angle formed by the bachelor and the positive particles. Contrarily to the other selections, this one is not standard in ALICE; it has been introduced in 2020 by \cite{silvadealbuquerqueMultistrangeHadronsPb2019}. At that time, a structure in the invariant mass distribution of \rmXi and \rmOmega, similar to the one in \figs\ref{fig:WrongPA}, was observed in Pb-Pb collisions. It turned out that the bump background, between 1.28 and 1.31 \gmass on \figs\ref{fig:XiMinusWrongPA} and \ref{fig:XiPlusWrongPA}, originates from an erroneous track association in the cascade reconstruction. 

A V0 decays into a baryon \proton/\pbar and a \rmPiMinus/\rmPiPlus, depending on whether this is a \rmLambda or \rmAlambda. In the situation where another negative/positive track in the event passes close by the proton/anti-proton, the reconstruction algorithm may interpret that as a V0 decay; this track plays the role of the negative/positive daughter particle of a \rmLambdaPM, and the proton/anti-proton corresponds to its positive/negative daughter particle. On the other hand, the \rmPiMinus/\rmPiPlus daughter of the actual \rmLambdaPM is combined to other particles, and most likely to the previously ill-formed V0. In such case, it acts like the bachelor particle of a cascade decay. In other words, while the actual topology is depicted in \fig\ref{fig:WrongV0}, it is reconstructed as a cascade, as illustrated in \fig\ref{fig:TrueV0}.

The analysis \cite{silvadealbuquerqueMultistrangeHadronsPb2019} investigated different strategies in order to remove this background contamination. In the end, the best option consists in rejecting candidates with a small pointing angle for the actual V0, \ie the pointing angle between the bachelor and the proton, as shown in \fig\ref{fig:WrongPACut}.


\begin{figure}[t]
\hspace*{-1.5cm}
\subfigure[]
{
	\includegraphics[width=0.6\textwidth]{Figs/Chapter5/InvMassXiMinus_WrongPA.eps}
	\label{fig:XiMinusWrongPA}
}
\subfigure[]
{
	\includegraphics[width=0.6\textwidth]{Figs/Chapter5/InvMassXiPlus_WrongPA.eps}
	\label{fig:XiPlusWrongPA}
}
\hspace*{-1.5cm}	
\subfigure[]
{
	\includegraphics[width=0.6\textwidth]{Figs/Chapter5/InvMassOmegaMinus_WrongPA.eps}
	\label{fig:OmegaMinusWrongPA}
}
\subfigure[]
{
	\includegraphics[width=0.6\textwidth]{Figs/Chapter5/InvMassOmegaPlus_WrongPA.eps}
	\label{fig:OmegaPlusWrongPA}
}	
	\caption{Invariant mass distribution of \rmXiM (a), \rmAxiP (b), \rmOmegaM (c) and \rmAomegaP (d) in pp at \sqrtS = 13 \tev. These have been obtained using the cuts in \tab\ref{tab:CascadeSelections} (red markers), except for the bachelor-proton pointing angle selection in black. This comparison shows the latter selection manages to remove a structure in the invariant mass distribution while preserving the population under the peak. Notice the log-scale on the y-axis, that puts into perspective the signal and background levels.}
	\label{fig:WrongPA}
\end{figure}

\begin{figure}[t]
%\centering
\hspace*{-2.cm}
\subfigure[]
{
	\includegraphics[width=0.32\textwidth]{Figs/Chapter5/WrongV0.png}
	\label{fig:WrongV0}
}
\subfigure[]
{
	\includegraphics[width=0.32\textwidth]{Figs/Chapter5/TrueV0.png}
	\label{fig:TrueV0}
}
\subfigure[]
{
	\includegraphics[width=0.4\textwidth]{Figs/Chapter5/WrongPACut.png}
	\label{fig:WrongPACut}
}
	\caption{Invariant mass distribution of \rmXiM (a), \rmAxiP (b), \rmOmegaM (c) and \rmAomegaP (d) in pp at \sqrtS = 13 \tev. These have been obtained using the cuts in \tab\ref{tab:CascadeSelections} (red markers), except for the bachelor-proton pointing angle selection in black. This comparison shows the latter selection manages to remove a structure in the invariant mass distribution while preserving the population under the peak.}
	\label{fig:WrongTopology}
\end{figure}

\subsection{Mass measurement}
\label{subsec:MassExtraction}

\subsubsection{Principles of mass extraction}
\label{subsubsec:PrinciplesOfMassExtraction}

Out of all the candidates passing the above selection criteria, there contains true V0s/cascades -- depending on the particle of interest -- and background candidates. Taken individually, they are undistinguisable. The separation of these two can only be achieved statistically, based on the analysis of the invariant mass spectrum.

The invariant mass of each candidate is calculated, as explained in \Sec\ref{subsubsec:CascadeFormation} and \Sec\ref{subsubsec:InvariantMassSelection}, and sorted according to their electric charge in order to separate the particles from the anti-particles. The V0s being electrically neutral, they follow a different approach: since the \rmKzeroS decays into two particles of the same nature --- a \rmPiPlus and a \rmPiMinus ---, it is hopeless to try separating particles and anti-particles. This is not the case of \rmLambda and \rmAlambda, though. However, it may happen that the same V0 candidate passes the particle and anti-particle selections in \tab\ref{tab:V0Selections}. To avoid such double-counting, each candidate needs to go through the \rmLambda selections first. If it satisfies all conditions, it is labeled as \rmLambda and we move to the next candidate. Otherwise, it is checked against the requirements for a \rmAlambda baryon.

On one hand, most of the background candidates originate from a random association of two or three tracks. Those tracks being uncorrelated, the corresponding invariant mass spectrum should be flat or decreasing with the invariant mass value. On the other hand, the invariant mass of true V0s/cascades should be close to the tabulated mass \mPDG, such that there emerges an overpopulated region taking the shape of a peak. The \figs\ref{fig:InvMassCascades} show the invariant mass spectra of \rmXi and \rmOmega.  One can see that the signal for each species sits on top of a small background.\\

\begin{figure}[!t]
%\centering
\hspace*{-1.5cm}
\subfigure[]{
	\includegraphics[width=0.6\textwidth]{Figs/Chapter5/InvMassXiMinus_ModifiedGaussian.eps}
	\label{fig:XiMinus_ModGaussian}
} 
\subfigure[]{
	\includegraphics[width=0.6\textwidth]{Figs/Chapter5/InvMassXiPlus_ModifiedGaussian.eps}
	\label{fig:XiPlus_ModGaussian}
} 
\hspace*{-1.5cm}
\subfigure[]{
	\includegraphics[width=0.6\textwidth]{Figs/Chapter5/InvMassOmegaMinus_ModifiedGaussian.eps}
	\label{fig:OmegaMinus_ModGaussian}
} 
\subfigure[]{
	\includegraphics[width=0.6\textwidth]{Figs/Chapter5/InvMassOmegaPlus_ModifiedGaussian.eps}
	\label{fig:OmegaPlus_ModGaussian}
}  
\caption{Invariant mass distribution of \rmXiM (a), \rmAxiP (b), \rmOmegaM (c) and \rmAomegaP (d) hyperons in pp collisions at \sqrtS = 13 \tev. Here, the peak is modeled by a modified Gaussian, and the background by a first order polynomial. Each distribution comes with an additional panel representing consistency between the data and the fit model, in the form of a ratio. The error bars encompasses the uncertainties on both quantities.}
	\label{fig:InvMassCascades}
\end{figure}

To isolate the signal from the background, a fit of the invariant mass spectra is performed using the sum of two functions: one for modeling the signal peak, the other for describing the background. Several functions can be considered, as discussed in \Sec\ref{subsubsec:SignalBackShape}. In \figs\ref{fig:InvMassCascades}, the peak is represented by a modified Gaussian \cite{atlascollaborationKshortLambdaProduction2012} and the background by a linear function. Whatever their shape, the fitting procedure is performed with the maximum (log-)likelyhood method.

If the procedure manages to converge, this fit allows to measure the mass of the considered particle: it corresponds to the centre of the invariant mass peak, given by the position of the maximum of the signal function denoted as $\mu$. The width of the peak -- the parameter $\sigma$ -- provides an estimation of the mass resolution. The uncertainties on both quantities come from the errors returned by the fitting procedure.

From these parameters, two regions of interest can be delimited:
\begin{itemize}
\item[$\bullet$] the peak region, containing all the signal\footnote{More precisely, considering the definition of the peak region in this analysis, it should contain approximately 99.99995\% (\ie a $5 \sigma$ significance level) of the true V0s/cascades measured.} and some background, is defined in $\left[ \mu - 5 \sigma ; \mu + 5 \sigma \right]$;
\item[$\bullet$] the side-bands region, solely constituted of background, consists in two bands of the same width\footnote{As a side note: the two side-bands do not need to be of the same size, but it avoids dealing with a scaling factor when comparing their total area to the one in the peak region. Most often, they have different widths because of an asymmetry in the invariant mass distribution, such as the structure reported in \Sec\ref{subsubsec:InvMassStructure} \cite{alicecollaborationProductionLightflavorHadrons2020}.}, surrounding the peak region and covering the range $\left[ \mu - 12 \sigma ; \mu - 7 \sigma \right] \bigcup \left[ \mu + 7 \sigma ; \mu + 12 \sigma \right]$.
\end{itemize}
Hence, the amount of raw signal and background can be evaluated. The peak ($S+B$) and background ($B$) populations are estimated by counting the
number of candidates in their respective regions. The raw signal ($S$) in the peak region is obtained by subtracting the background from the peak population, that is $S = (S+B) - B$.

In \figs\ref{fig:InvMassCascades}, all the fit are of reasonably good quality. The mass peak sits on a small background; 1 237 666 $\pm$ 1162 \rmXiM (1 168 882 $\pm$ 1128 \rmAxiP) and 65 232 $\pm$ 277 \rmOmegaM (63 842 $\pm$ 274 \rmAomegaP) were reconstructed with purities above 90\%, as shown in \tab\ref{tab:FitQuantities}.

\begin{table}[h]
    \centering
    \begin{tabular}{b{5.35cm}@{\hspace{1cm}} b{2cm}@{\hspace{0.5cm}} b{2cm}@{\hspace{0.5cm}} b{1.5cm}@{\hspace{0.5cm}} b{1.5cm}@{\hspace{0.1cm}}}
    \noalign{\smallskip}\hline\noalign{\smallskip}
	Particle & \rmXiM & \rmAxiP & \rmOmegaM & \rmAomegaP \\	
    \noalign{\smallskip}\hline \noalign{\smallskip}
    Reduced $\chi^2$ & 12.689 & 11.273 & 5.051 & 4.707\\
    	Raw signal, $S$ &  1 237 666 & 1 168 882 & 65 232 & 63 842\\
    	Background, $B$ & 55 375 & 51 269 & 5758 & 5490 \\
    	$S/B$ & 22.4 & 22.8 & 11.4 & 11.7 \\
    	Purity, $S/(S+B)$ & 95.7\% & 95.8\% & 91.8\% & 92.1\% \\
    Signal significance, $S/\sqrt{S+B}$ & 1089 & 1059 & 245 & 243 \\
    \noalign{\smallskip}\hline\noalign{\smallskip}
    \end{tabular}
    \caption{Results from the fit of the invariant mass distributions in \fig\ref{fig:InvMassCascades} concerning the samples of \rmXiM, \rmAxiP, \rmOmegaM and \rmAomegaP. Therefore, this table reports the reduced $\chi^{2}$, raw signal, background, ratio $S/B$, purity and signal significance.}\label{tab:FitQuantities}
\end{table}

\subsubsection{Shape of the peak functions}
\label{subsubsec:SignalShape}

Since the mass extraction depends on the peak description, it is crucial to identify functional forms that reproduce accurately its shape. Different functions have been studied in MC simulations, based solely on true V0/cascade candidates. Thus, the invariant mass spectra contains no background candidates and follows approximately a Gaussian distribution centred on the injected mass, which usually corresponds to the PDG mass. The objective here is to define a list of functions, that describe correctly the shape of the invariant mass peak and are characterised by a resonably good reduced $\chi^{2}$. Two types of functional forms are considered: symmetric and asymmetric functions. 

\paragraph{Symmetric function:} Due to the detector smearing, the core of the invariant mass distribution exhibits a quasi-Gaussian shape; in that respect, one may favour symmetric functions. The tails of the distribution, however, are usually not Gaussian-like, and thus not well described by this class of functions. This is due to the contribution of particles with different transverse momentum; as the \pT resolution varies with the transverse momentum and relates to the width of the invariant mass peak, the measured distribution consists in fact in an infinite sum of invariant mass distribution, each with a different width. Always with the aim of employing an symmetric function, the solution thus consists to take an infinite sum of Gaussian with a common mean\footnote{A more unusual approach would be to consider an infinite sum of Gaussian, each with a different mean. This would be relevant if the mass measurement is biased, in such a way that mass changes with momentum for example. In such case, a non-trivial question arises as of what value to take as a final mass measurement. As of today, there is still no clear answer.}. In the present analysis, it has been observed that three Gaussians (\eq\ref{eq:Gaus}) already offer a resonably good fit quality. Another option is to resort to slightly modified versions of a Gaussian, such that it provides a better description of the tails of the distribution (\eq\ref{eq:ModifiedGaus}).

\begin{itemize}
\item[$\bullet$] \textbf{Triple Gaussian}:
	\begin{equation}
	\dNdX{\mInv[]} = A_{1} \cdot \exp \left[ - \dfrac{ (\mInv[] - \mu )^2}{ 2 \sigma_{1}^2} \right] + A_{2} \cdot \exp \left[ - \dfrac{ (\mInv[] - \mu )^2}{ 2 \sigma_{2}^2} \right] + A_{3} \cdot \exp \left[ - \dfrac{ (\mInv[] - \mu )^2}{ 2 \sigma_{3}^2} \right]
	\label{eq:Gaus}
	\end{equation}
	with $A_{1}$, $A_{2}$, $A_{3}$ the amplitudes of the first, second and third Gaussian, $\mu$ the common mean value, and $\sigma_{1}$, $\sigma_{2}$, $\sigma_{3}$ the width of the first, second and third Gaussian.
%	
%\item \textbf{Double Gaussian} : it consists in a sum of two Gaussian functions with different parameters but the mean value which is common.
%	\begin{equation}
%	\dNXdX{\rmXiPM(\rmOmegaPM)}{\mInvIdx{\rmLambdaPM \piPlusMinus (\rmLambdaPM \Kplusmin)}} = A_{1} \cdot \exp \left[ - \dfrac{ (\mInvIdx{\rmLambdaPM \piPlusMinus (\rmLambdaPM \Kplusmin)} - \mu )^2}{ 2 \sigma_{1}^2} \right] + A_{2} \cdot \exp \left[ - \dfrac{ (\mInvIdx{\rmLambdaPM \piPlusMinus (\rmLambdaPM \Kplusmin)} - \mu )^2}{ 2 \sigma_{2}^2} \right]
%	\end{equation}\label{eq:DoubleGaus}
%	where $A_1$ and $A_2$ are the respective amplitudes of the two Gaussian, $\mu$ corresponds to the center of the peak (common for the two Gaussian), and their widths are denoted as $\sigma_1$ and $\sigma_2$.
%	
\item[$\bullet$] \textbf{Modified Gaussian} \cite{atlascollaboration2012}:
	\begin{equation}
	\dNdX{\mInv} = A \cdot \exp \left[ - \frac{1}{2} u^{1 + \frac{1}{1+ 0.5 u}} \right] \quad ; \quad  u = \left\rvert \frac{\mInv - \mu }{\sigma} \right\rvert
	\end{equation}\label{eq:ModifiedGaus}
	with $A$ the normalization, $\mu$ the mean, and $\sigma$ the width.\\
	
\end{itemize}

\paragraph{Asymmetric function:} Previous functions are all different flavours of Gaussian, and so are all symmetric. However, this is not necessarily the case for the tails of the invariant mass distribution. In such case, an asymmetric function seems more suited for describing the peak. Among those appears the Bukin function  \cite{niel2021}, that is modified Novosibirsk distribution, constructed from the convolution of a Gaussian and an exponential distributions. It is typically used to fit the invariant mass of \rmJpsi.

\begin{itemize}
\item[$\bullet$] \textbf{Bukin}:
	\begin{equation}
	\dNdX{\mInv} = 
		\begin{cases}
	      A \cdot \exp \left[ \rho_{\rm L} \frac{(u-x_{\rm L})^2}{(\mu-x_{\rm L})^2} - \ln(2) + 4 \cdot \ln(2)  \frac{(u-x_{\rm L})}{2 \sigma \sqrt{ 2  \ln 2 }} \cdot  \frac{\xi}{\sqrt{\xi^2+1} + \xi}  \frac{\sqrt{\xi^2+1}}{(\sqrt{\xi^2+1}-\xi)^2} \right], \qquad u\leq x_{\rm L} \\
	      \\
	      A \cdot \exp \left[ -\ln(2) \cdot \left( \frac{ \ln(1 + 4 \xi \sqrt{\xi^2+1} \frac{u - \mu}{2 \sigma \sqrt{2 \ln 2}}) }{ \ln( 1 + 2 \xi (\xi - \sqrt{\xi^2+1})) } \right)^2 \right], \qquad  x_{\rm L} < u < x_{\rm R} \\
	      \\
	      A \cdot \exp \left[ \rho_{\rm R} \frac{(u-x_{\rm R})^2}{(\mu-x_{\rm R})^2} - \ln(2) + 4 \cdot \ln(2) \frac{(u-x_{\rm R})}{2 \sigma \sqrt{ 2  \ln 2 }} \cdot  \frac{\xi}{\sqrt{\xi^2+1} + \xi} \frac{\sqrt{\xi^2+1}}{(\sqrt{\xi^2+1}-\xi)^2} \right], \qquad u \geq x_{\rm R} 
	     \end{cases}
	\end{equation}\label{eq:Bukin}
	with 
	\begin{equation}
		x_{\rm L, R} = \mu + \sigma \sqrt{ 2 \ln 2 } \left( \frac{ \xi}{ \sqrt{\xi^2 + 1 } } \mp 1 \right)
	\end{equation}
	where $u$ coincides with \mInv, $A$ is the normalization parameter, $\mu$ and $\sigma$ are the mean and the width of the peak, $\xi$ is an asymmetry parameter, $\rho_{\rm L}$ and $\rho_{R}$ are left and right exponential tail coefficients \cite{verkerke2008}.
	
\item[$\bullet$] \textbf{Double Sided Crystal Ball} \cite{atlascollaborationSearchResonancesDiphoton2016}:
	\begin{equation}
	\dNdX{\mInv} = 
		\begin{cases}
	      A \cdot \left(\frac{n_{\rm L}}{\alpha_{\rm L} (n_{\rm L} - \alpha_{\rm L}^{2} - u \alpha_{\rm L})}\right)^{n_{L}} \exp \left[ -0.5  \alpha_{\rm L}^{2} \right] , \qquad u < -\alpha_{\rm L} \\
	      \\
	      A \cdot \exp \left[ -0.5 u^{2} \right], \qquad  -\alpha_{\rm L} \leq u \leq \alpha_{\rm R} \\
	      \\
	      A \cdot \left(\frac{n_{\rm R}}{\alpha_{\rm R} (n_{\rm R} - \alpha_{\rm R}^{2} + u \alpha_{\rm R})}\right)^{n_{R}} \exp \left[ -0.5  \alpha_{\rm R}^{2} \right] , \qquad u < \alpha_{\rm R} 
	     \end{cases}
	\end{equation}\label{eq:DoubleSidedCrystalBallFunction}
	with $u$ equals $\left(\mInv - \mu\right)/\sigma_{L}$ for $\mInv - \mu < 0$ and $\left(\mInv - \mu\right)/\sigma_{R}$ for $\mInv - \mu > 0$, $A$ is the normalization parameter, $\mu$ is the peak position, $\sigma_{\rm L}$ and $\sigma_{\rm R}$ parametrise the position where the peak starts to follow a power law towards the low and high mass values respectively, of exponents $n_{\rm L}$ and $n_{\rm R}$.

\end{itemize}

\subsubsection{Shape of the background functions}
\label{subsubsec:BackgroundShape}

The origin of the data sample purity has to be found in the (very) tight cut on the cosine of pointing angle of the cascade candidate in \tab\ref{tab:CascadeSelections}. As a matter of fact, this selection has been tuned to reach such level of purity. Contrarily to the peak shape, the form of background is \textit{a priori} lesser known. For that reason, it is essential to control the level of background, and most particularly its profile, such that it can be modeled by one of the expected functional form.

For the background, different functional forms are considered :

\begin{itemize}
\item \textbf{Constant}: one may suspect the combinatorial background to be \textit{a priori} unstructured. In such case, it should follow an uniform distribution, and thus can be approximated by a constant function.
\item \textbf{Linear}: The previous description can be refined by considering that the number of tracks decreases with momentum. Consequently, the misassociation of low momentum tracks should dominate the combinatorial background at the low invariant mass values, whereas the high values originate from tracks with higher momentum. Hence, the background reduces with the invariant mass value. This decrease may be parametrised, at first order, by a linear function.
\item \textbf{Exponential}: Alternatively, the background can also be decreased by an exponential function.
\item \textbf{Second order polynomial}: In case the background turns out not to be purely combinatorial, but has a physics origin like, for instance particles produced from the interaction with the detector material. In such scenario, the background may have a specific structure, that needs to be described by more parameters than in the above functions. To that end, a second order polynomial is also considered for modeling the background.
\end{itemize}

\subsubsection{Correction on the extracted mass}
\label{subsubsec:CorrectionOnTheExtractedMass}

Although the functions in \Sec\ref{subsubsec:SignalBackShape} describe well the invariant mass peak, the extracted mass does not agree with the injected mass, the PDG mass, as shown in \fig. This seemingly bias may stem from several elements. It can be due to the way data are processed, that might overestimate the reconstructed mass in a systematic manner. The analysis, and particularly the employed selections, may introduce a distortion in the invariant mass distribution, resulting in a different mass than the expected one. The fit procedure could also be the origin of such inconsistency; for instance, one of the tails may pre-dominate the procedure and drive the parameters in a certain direction.

Anyhow, in order to correct for any bias due to the data processing, the analysis or the fit procedure, an offset is applied on the extracted mass in simulated events such that it coincides with the injected value. It follows that this correction is then reported on the measured mass in real data. However, such a correction assumes a good agreement between the data and MC. To ensure that, the simulation is re-weighted to match the \pT spectra from the data.

This re-weighting procedure starts off by extracting the raw \pT spectra in the data. Similarly to the estimation of the amount of raw signal in \Sec\ref{subsubsec:PrinciplesOfMassExtraction}, the latter is given by subtracting the \pT spectrum in the side-bands region from the one in the peak region. It is then compared to the injected transverse momentum distribution of true V0/cascade candidates; the ratio of the \pT spectra in the data and MC provides the weighting factors.


\begin{figure}[!t]
%\centering
\hspace*{-1.5cm}
\subfigure[]{
	\includegraphics[width=0.6\textwidth]{Figs/Chapter5/RawPtSpectra_Xi.eps}
	\label{fig:XiMinus_ModGaussian}
} 
\subfigure[]{
	\includegraphics[width=0.6\textwidth]{Figs/Chapter5/WeightingFactors_Xi.eps}
	\label{fig:XiPlus_ModGaussian}
} 
\hspace*{-1.5cm}
\subfigure[]{
	\includegraphics[width=0.6\textwidth]{Figs/Chapter5/RawPtSpectra_Omega.eps}
	\label{fig:OmegaMinus_ModGaussian}
} 
\subfigure[]{
	\includegraphics[width=0.6\textwidth]{Figs/Chapter5/WeightingFactors_Omega.eps}
	\label{fig:OmegaPlus_ModGaussian}
}  
\caption{Invariant mass distribution of \rmXiM (a), \rmAxiP (b), \rmOmegaM (c) and \rmAomegaP (d) hyperons in pp collisions at \sqrtS = 13 \tev. Here, the peak is modeled by a modified Gaussian, and the background by a first order polynomial. Each distribution comes with an additional panel representing consistency between the data and the fit model, in the form of a ratio. The error bars encompasses the uncertainties on both quantities.}
	\label{fig:PtSpectra}
\end{figure}


Once the simulated data have been re-weighted, the mass offset observed in MC with respect to the injected mass is assessed, corrected and taken into account in the mass measurement in real data. The \tab\ref{tab:MCMassOffset} presents these corrections as well as the corrected mass values. From these derive the (relative) mass difference between particle and anti-particle, given by
\begin{equation}
\frac{\Delta \mu}{\mu}=  2 \cdot \frac{\mu_{\textsc{part.}}-\mu_{\overline{\textsc{part.}}}}{\mu_{\textsc{part.}}+\mu_{\overline{\textsc{part.}}}}.
\label{eq:MassDifference}
\end{equation}
Its (statistical) uncertainty is obtained via propagation of the ones on the mass values, assuming there is no correlation between the particle and anti-particle measurements -- \textit{a priori} correct, since $\mu_{\textsc{part.}}$ and $\mu_{\overline{\textsc{part.}}}$ have been extracted independently\footnote{The facts that i) the particle and anti-particle do not share the same data sample (\Sec\ref{subsubsec:PrinciplesOfMassExtraction}), and ii) the fitting procedure is run separately guarantee the independence of the mass measurements.}--,
\begin{equation}
\sigma_{\Delta \mu /\mu }=  4 \cdot \sqrt{ \left(\frac{-\mu_{\overline{\textsc{part.}}}}{\left(\mu_{\textsc{part.}} + \mu_{\overline{\textsc{part.}}} \right)^{2}}\right)^{2} \sigma_{\mu_{\textsc{part.}}}^{2} + \left(\frac{\mu_{\textsc{part.}}}{\left(\mu_{\textsc{part.}} + \mu_{\overline{\textsc{part.}}} \right)^{2}}\right)^{2} \sigma_{\mu_{\overline{\textsc{part.}}}}^{2} }.
\label{eq:MassDifferenceUncertainty}
\end{equation}
The \tab\ref{tab:MCMassDiffOffset} shows mass difference for \rmXi and \rmOmega, in the data and MC, as well as the corrected value.

\begin{table}[!t]
    \centering
    \footnotesize
    \begin{tabular}{b{2.5cm}@{\hspace{0.5cm}} b{2.5cm}@{\hspace{0.5cm}} b{2.5cm}@{\hspace{0.5cm}} b{2.5cm}@{\hspace{0.5cm}} b{2.5cm}@{\hspace{0.5cm}}}
    \noalign{\smallskip}\hline\noalign{\smallskip}
    \bf Particle & \bf \rmXiM & \bf \rmAxiP & \bf \rmOmegaM & \bf \rmAomegaP \\
    \noalign{\smallskip}\hline \noalign{\smallskip}    
    Offset in data & $0.004 \pm 0.004$  & $0.055\pm 0.004$ & $0.090\pm 0.014$ & $0.066 \pm 0.014$ \\
    Offset in MC & $-0.127 \pm 0.003$  & $-0.125\pm 0.003$ & $-0.023\pm 0.004$ & $-0.005 \pm 0.004$ \\
    	Corrected mass & $1321.841 \pm 0.005$ & $1321.890 \pm 0.005$ & $1672.517 \pm 0.015$ & $1672.511 \pm 0.015$\\
    \noalign{\smallskip}\hline\noalign{\smallskip}
    \end{tabular}
    \caption{Measurements of the mass offset with respect to the PDG value (coinciding with the injected mass in MC) in the data and MC, as well as the final corrected masses of $\Xi^{-}$, $\overline{\Xi}^{+}$, $\Omega^{-}$, $\overline{\Omega}^{+}$. The uncertainties on the mass values correspond only to the statistical one. These measurements have been obtained using the selections in \tab\ref{tab:CascadeSelections}, a modified Gaussian for the peak modelisation and a linear function for the background (in the data only).}\label{tab:MCMassOffset}
\end{table}

\begin{table}[!t]
    \centering
%    \footnotesize
    \begin{tabular}{b{7.5cm}@{\hspace{0.5cm}} b{3cm}@{\hspace{0.5cm}} b{3cm}@{\hspace{0.5cm}}}
    	\noalign{\smallskip}\hline \noalign{\smallskip}    
    \bf Particle & \bf \rmXi & \bf \rmOmega\\
    \noalign{\smallskip}\hline \noalign{\smallskip}  
    Mass difference offset in data ($\times 10^{-5}$) & $0.004 \pm 0.004$  & $0.004 \pm 0.004$ \\
    Mass difference offset in MC ($\times 10^{-5}$)& $0.004 \pm 0.004$ & $0.004 \pm 0.004$  \\
    	Corrected mass difference ($\times 10^{-5}$) & $0.004 \pm 0.004$ & $0.004 \pm 0.004$ \\
    
    \noalign{\smallskip}\hline\noalign{\smallskip}
    \end{tabular}
    \caption{Measurements of the mass difference in the data and MC, as well as the final corrected mass difference for $\Xi^{\pm}$ and $\Omega^{\pm}$. The uncertainties on the mass differences correspond only to the statistical one. These measurements have been obtained using the selections in \tab\ref{tab:CascadeSelections}, a modified Gaussian for the peak modelisation and a linear function for the background (in the data only).} 
    \label{tab:MCMassDiffOffset}
\end{table}

\section{Study of the systematic effects}

A study of the systematic effets -- also called \textit{systematic study} in the particle physicist's jargon -- consists in reviewing an analysis via the test of its different elements. As its name suggests, it involves identifying the source of systematic uncertainties that might affect the values of the extracted mass and their corresponding uncertainties. Usually, this is achieved by repeating the analysis with a few \say{minor} changes, hoping that no effect will be observed. In such case, meaning that the obtained values are consistent, then one could argue that the analysis is free of systematic effect and under control: no additional measure are requested. On the contrary, a large deviation in the values indicates the presence of a systematic effect, that should be treated seriously. 

In pratice, one needs to define what \say{small} and \say{large} deviations mean. If an analysis is performed in two different ways: the first approach gives the result $a_1$ with an uncertainty $\sigma_1$ ; the second $a_2$ with an uncertainty $\sigma_2$. The difference between the results is given by $\Delta = a_1 - a_2$ and the error on the difference by $\sigma_{\Delta} = \sqrt{ |\sigma_{1}^{2} - \sigma_{2}^{2} | }$. If the ratio $\Delta/\sigma_{\Delta}$ is greater than a certain threshold value -- denoted \sigmaBarlow and to be defined by the analyser --, this points out a systematic effect that requires further investigation. This approach is known as the \textit{Barlow criterion}.

As in cooking, what separates the good systematic study from the lesser good one is the choice of the seasoning, namely the choice of the threshold value. The larger the \sigmaBarlow, the more systematic effects would slip under the radar; conversely, the smaller the threshold, the higher the sensitivity to the systematic effects. Since the targeted precision on the mass and mass difference values is very low, the systematic effects must be well under control. Therefore, in the context of this analysis, the contribution of a potential source of systematics is said to be significant for $\sigmaBarlow\simeq 1$. \\

However, the presence of a systematic effect does not necessarily imply a systematic uncertainty. In fact, there are two possibilites. Either a systematic correction can be applied and the error on that correction will be quoted as the systematic uncertainty, or the correction may be difficult (or impossible) to derive and therefore the systematic uncertainty will have to fully encompass the imprecision induced to the systematic effect.

This treatement of the systematic biases corresponds to the one proposed by Roger Barlow \cite{barlow2000}\cite{barlow2002}. The following section presents the list of systematic sources studied for this analysis, with their estimated uncertainties or corrections.

\subsection{Topological and track selections}
\label{subsec:SystTopoAndTrackSelections}

\subsubsection{Influence on the mass extraction}
\label{subsubsec:SystTopoMass}

As explained in \Sec\ref{subsec:TopoReco}, the identification of the charged \rmXi and \rmOmega baryons relies on their characteristic cascade decay. The reconstruction of these decay topology revolves around, first, the association of two tracks to form \rmLambda candidates, and then these are matched with the remaining secondary tracks. In order to reduce the induced combinatorial background, various topological and kinematic cuts are being used. The choice of the employed cut values may obviously be the source of a bias. Such a systematic effect can be revealed by observing how a different set of selections affects the mass and its uncertainty.\\

The standard approach consists in varying individually each selection, while keeping the others at their reference value. Although it allows to address the bias induced by a given cut, this does not take into account the possible correlation between topological variables. For instance, a higher cut on cascade decay radius also implies that the \rmLambda daughter decays further away in the detector. To tackle that, one needs to build a matrix containing the correlation factors for each pair of selection variables.

However, a different approach is followed here. To go over the correlations between each variable, the sets of selections are randomly generated according to an uniform law, that spans over a certain variation range. The critical point of this study resides in the choice of the variation range, where a careful balance must be found: it should not be too \say{severe} at the risk of losing all the signal, or too \say{gentle} to cause any significant shift. It is considered as satisfactory when the induced signal shift reaches approximately 10\%\footnote{Note that this condition is applied for each topological cuts. For other selections, it may be difficult to satisfy such criterion as they act on the background rather than the signal. This is the case, for example, with the competing mass rejection that could never reach the 10\% signal variation threshold, even with an excessively vast range of variation.}. The \tabs\ref{tab:SystematicSelectionsXi} and \ref{tab:SystematicSelectionsOmega}, list the considered selection variables, with their variation range as well as the induced signal variation for \rmXi and \rmOmega respectively. As for the \rmKzeroS and \rmLambda, this is summarised in \tabs\ref{tab:SystematicSelectionsK0s} and \ref{tab:SystematicSelectionsLambda}. \\

\begin{table}[t]
    \centering
    \begin{tabular}{c|c|c}
    \noalign{\smallskip}\hline \noalign{\smallskip}
    \bf Track variable & Variation range & Signal variation \rmXiM (\rmAxiP) \\
    \noalign{\smallskip}\hline \noalign{\smallskip}
    Nbr of crossed TPC readout rows & $> \left[ 70 ; 90 \right]$ &  1\% (1\%)\\
    $\Nsigma^{\rm TPC}$ & $<\left[ 1 ; 3 \right] $ &  60\% (60\%)\\
    
    \noalign{\smallskip}\hline \noalign{\smallskip}
    \bf Topological variable & Variation range & Signal variation \rmXiM (\rmAxiP) \\
    \noalign{\smallskip}\hline \noalign{\smallskip}
    
    \multicolumn{3}{l}{\textbf{V0}} \\
    V0 decay radius (\cm) & $> \left[ 1.2 ; 8 \right]$ & 11\% (11\%)\\
    V0 cosine of pointing angle & $> \left[ 0.97 ; 0.998 \right]$ & 10\% (10\%)\\
    |$m$($V0$) - \mPDG\rmLambda| (\gmass) & $< \left[ 0.002 ; 0.007 \right]$ & 18\% (18\%)\\
    DCA proton to prim. vtx (\cm) & > $\left[ 0.04 ; 0.5 \right]$ & 28\% (28\%)\\
    DCA pion to prim. vtx (\cm) & > $\left[ 0.04 ; 0.95 \right]$ & 10\% (10\%)\\
    DCA V0 to prim. vtx (\cm) & > $\left[ 0.06 ; 0.2 \right]$ & 12\% (12\%)\\
    DCA between V0 daughters (std dev) & < $\left[ 0.4 ; 1.2 \right]$ & 12\% (12\%) \\
    \noalign{\smallskip}\hline \noalign{\smallskip}
    
    \multicolumn{3}{l}{\textbf{Cascade}} \\
    Cascade decay radius (\cm) & > $\left[ 0.5 ; 2.5 \right]$ & 11\% (11\%)\\
    Cascade Lifetime (\cm) & < $\left[ 1.6 ; 3.40 \right]$ \cTau & 40\% (40\%)\\
    DCA bachelor to prim. vtx (\cm) & > $\left[ 0.04 ; 0.5 \right]$ & 15\% (15\%) \\
    DCA between the cascade daughters (std dev) & < $\left[ 0.25 ; 1.2 \right]$ & 12\% (12\%)\\
    Cascade cosine of pointing angle & > $\left[ 0.995 ; 0.9995 \right]$ & 14\% (14\%)\\
    Bachelor-proton pointing angle (rad) & > $\left[ 0.02 ; 0.05 \right]$ & 11\% (11\%) \\
    
    \noalign{\smallskip}\hline \noalign{\smallskip}
    \end{tabular}
    \caption{Summary of the variation ranges on the topological and track selections employed in the \rmXiM and \rmAxiP reconstruction. The last column indicates the \textit{maximum} induced signal variation; for more details, look at \fig\ref{fig:SignalVariation_TopoSel_XiMinus} and \fig\ref{fig:SignalVariation_TopoSel_XiPlus}.}\label{tab:SystematicSelectionsXi}
\end{table}

\begin{table}[t]
    \centering
    \begin{tabular}{c|c|c}
    \noalign{\smallskip}\hline \noalign{\smallskip}
    \bf Candidate variable & Range & Signal variation \rmOmegaM (\rmAomegaP) \\
    \noalign{\smallskip}\hline \noalign{\smallskip}    
    Competing mass rejection (\gmass) & $> \left[ 0.006 ; 0.010 \right]$ & 0.9\% (0.9\%)\\
    
    \noalign{\smallskip}\hline \noalign{\smallskip}
    \bf Track variable & Range & Signal variation \rmOmegaM (\rmAomegaP) \\
    \noalign{\smallskip}\hline \noalign{\smallskip}
    Nbr of crossed TPC readout rows & $> \left[ 70 ; 90 \right]$ &  2.5\% (2.5\%)\\
    $\Nsigma^{\rm TPC}$ & $< \left[ 1 ; 3 \right] $ &  60\% (60\%)\\
    
    \noalign{\smallskip}\hline \noalign{\smallskip}
    \bf Topological variable & Range & Signal variation \rmOmegaM (\rmAomegaP) \\
    \noalign{\smallskip}\hline \noalign{\smallskip}
    
    \multicolumn{3}{l}{\textbf{V0}} \\
    V0 decay radius (\cm) & $> \left[ 1 ; 5.5 \right]$ & 11\% (11\%)\\
    V0 cosine of pointing angle & $> \left[ 0.97 ; 0.998 \right]$ & 17\% (17\%)\\
    |$m$($V0$) - \mPDG\rmLambda| (\gmass) & $< \left[ 0.002 ; 0.007 \right]$ & 17\% (17\%)\\
    DCA proton to prim. vtx (\cm) & $> \left[ 0.04 ; 0.5 \right]$ & 34\% (34\%)\\
    DCA pion to prim. vtx (\cm) & $> \left[ 0.04 ; 0.75 \right]$ & 10\% (10\%) \\
    DCA V0 to prim. vtx (\cm) & $> \left[ 0.06 ; 0.2 \right]$ & 14\% (14\%)\\
    DCA between V0 daughters (std dev) & $< \left[ 0.4 ; 1.2 \right]$ & 11\% (11\%)\\
    \noalign{\smallskip}\hline \noalign{\smallskip}
    
    \multicolumn{3}{l}{\textbf{Cascade}} \\
    Cascade decay radius (\cm) & $> \left[ 0.5 ; 1.6 \right]$ & 12\% (12\%)\\
    Cascade Lifetime (\cm) & $< \left[ 1.6 ; 3.40 \right]$ \cTau & 14\% (14\%)\\
    DCA bachelor to prim. vtx (\cm) & $> \left[ 0.05 ; 0.2 \right]$ & 13\% (13\%)\\
    DCA between the cascade daughters (std dev) & $< \left[ 0.15 ; 1.2 \right]$ & 12\% (12\%)\\
    Cascade cosine of pointing angle & $> \left[ 0.995 ; 0.9995 \right]$ & 17\% (17\%)\\
    Bachelor-proton pointing angle & $> \left[ 0.02 ; 0.05 \right]$ & 13\% (13\%)\\
    
    \noalign{\smallskip}\hline \noalign{\smallskip}
    \end{tabular}
    \caption{Summary of the variation ranges on the topological and track selections employed in the \rmOmegaM and \rmAomegaP reconstruction. The last column indicates the \textit{maximum} induced signal variation; for more details, look at \fig\ref{fig:SignalVariation_TopoSel_OmegaMinus} and \fig\ref{fig:SignalVariation_TopoSel_OmegaPlus}.}\label{tab:SystematicSelectionsOmega}
\end{table}

The analysis is repeated for each randomly generated set of cuts $i$, as detailed in \Sec\ref{subsec:MassExtraction}, meaning that a mass $\mu_{i}$ and its uncertainty $\sigma_{i}$ are extracted from the fit of the corresponding invariant mass distribution in the data and MC. However, only the values passing the following criteria are retained:

\begin{itemize}
\item[$\bullet$] the fitting procedure must have converged;
\item[$\bullet$] to ensure a good fit quality, its reduced $\chi^{2}$ needs to be relatively to the unity, $\rmChiSquareNDF < 5$;
\item[$\bullet$] the uncertainties on the mass value are expected to be below the \mmass. Since the \rmXi and \rmOmega masses are of the order of \gmass, a $\sigma_{\mu_{i}}$ at the level of 0.1\% of $\mu_{i}$ represents an uncertainty greater than 1 \mmass. In order to remove outliers, it is required that $\sigma_{\mu_{i}}/\mu_{i} < 0.1\%$.
\end{itemize}

Under these conditions and over a sufficiently large number of sets of cuts, the distributions $\mu_{i}$ and $\sigma_{\mu_{i}}$ can be built. These offer the opportunity to re-qualify the mass and its uncertainties:
\begin{itemize}
\item[$\bullet$] the \textit{measured mass} corresponds to the mean value of the $\mu_{i}$ distribution,
\item[$\bullet$] the \textit{systematic uncertainty} due to the candidate selections is the standard deviation of the $\mu_{i}$ distribution,
\item[$\bullet$] and the \textit{statistical uncertainty} is given by the mean value of the $\sigma_{\mu_{i}}$ distribution.
\end{itemize}
As opposed to most analyses, this re-definition allows to overcome the dependence on a reference set of cuts, making the analysis \textit{in principle} more robust.\\

\begin{figure}[!p]
%\centering
\hspace*{-1.5cm}
\subfigure[]{
	\includegraphics[width=0.6\textwidth]{Figs/Chapter5/MassVsNbrOfCutSets\_Xi.eps}
	\label{fig:MassVsNbrOfCutSetsXi}
} 
\subfigure[]{
	\includegraphics[width=0.6\textwidth]{Figs/Chapter5/MassVsNbrOfCutSets\_Omega.eps}
	\label{fig:MassVsNbrOfCutSetsOmega}
} 
\hspace*{-1.5cm}
\subfigure[]{
	\includegraphics[width=0.6\textwidth]{Figs/Chapter5/StatErrVsNbrOfCutSets\_Xi.eps}
	\label{fig:StatErrVsNbrOfCutSetsXi}
} 
\subfigure[]{
	\includegraphics[width=0.6\textwidth]{Figs/Chapter5/StatErrVsNbrOfCutSets\_Omega.eps}
	\label{fig:StatErrVsNbrOfCutSetsOmega}
} 
\hspace*{-1.5cm}
\subfigure[]{
	\includegraphics[width=0.6\textwidth]{Figs/Chapter5/SystErrVsNbrOfCutSets\_Xi.eps}
	\label{fig:SystErrVsNbrOfCutSetsXi}
} 
\subfigure[]{
	\includegraphics[width=0.6\textwidth]{Figs/Chapter5/SystErrVsNbrOfCutSets\_Omega.eps}
	\label{fig:SystErrVsNbrOfCutSetsOmega}
}  
\caption{Relative measured mass as well as its statistical and systematic uncertainties in pp collisions at \sqrtS = 13 \tev as a function of the number of cut sets, for \rmXi in (a), (c), (e) and \rmOmega in (b), (d), (f) respectively. The quantities on the y-axis are relative to the value taken as the final measurement. In this case, it corresponds to the quantity for 20 000 different sets of cuts. Here, the peak is modeled by a modified Gaussian, and the background by a first order polynomial. The error bars represents the uncertainty on the evaluation of the mean or standard deviation.}
	\label{fig:MassVsNentries}
\end{figure}
%\clearpage

The above quantities being extracted from a finite sample, one could expect them to depend on the number of cut sets, $N$. The stability of the results with the amount of sets employed has been studied and is shown on \fig\ref{fig:MassVsNentries}. At first, the mass value, its statistical and systematic uncertainties fluctuate with the $N$, until they reach a plateau region at approximately 5000-6000 different sets of cuts. Such amount should thus suffice to perform the mass measurement. However, in order to a guarantee an excellent stability, 20 000 sets are being used.

The output results of this procedure are presented in the table \ref{tab:SystTopoKineSelections}.

\begin{table}[h]
    \centering
    \begin{tabular}{cccc|ccc}

%    \begin{tabular}{b{2cm}@{\hspace{0.5cm}} b{3cm}@{\hspace{0.5cm}} b{2cm}@{\hspace{0.5cm}} b{2cm}@{\hspace{0.5cm}} b{5cm}@{\hspace{0.5cm}} b{3cm}@{\hspace{0.5cm}} b{3cm}@{\hspace{0.5cm}}}
    \noalign{\smallskip}\hline \noalign{\smallskip}
    \bf Particle & \bf Measured & \multicolumn{2}{c|}{\bf Uncertainty} & \bf Measured & \multicolumn{2}{c}{\bf Uncertainty}\\
    & \bf mass & \bf stat. & \bf syst. & \bf mass difference & \bf stat. & \bf syst.\\
    & (\mmass) & (\mmass) & (\mmass) & ($\times 10^{-5}$) & ($\times 10^{-5}$) & ($\times 10^{-5}$) \\
    \noalign{\smallskip}\hline \noalign{\smallskip}
    \rmKzeroS & 497.737 & 0.003 & 0.010 & / & / & / \\
	\noalign{\smallskip}\hline \noalign{\smallskip}
    \rmLambda & 1115.618 & 0.002 & 0.011 & \multirow{2}{*}{4.78} & \multirow{2}{*}{0.17} & \multirow{2}{*}{0.14} \\
	\rmAlambda & 1115.671 & 0.002 & 0.012 & & & \\
    \noalign{\smallskip}\hline \noalign{\smallskip}
    \rmXiM & 1321.728 & 0.004 & 0.016 & \multirow{2}{*}{3.95} & \multirow{2}{*}{0.37} & \multirow{2}{*}{0.39} \\
	\rmAxiP & 1321.780 & 0.004 & 0.019 & & & \\
    \noalign{\smallskip}\hline \noalign{\smallskip}
    \rmOmegaM & 1672.536 & 0.014 & 0.015 & \multirow{2}{*}{-1.31} & \multirow{2}{*}{1.14} & \multirow{2}{*}{0.76} \\ 
    \rmAomegaP &  1672.514 & 0.014 & 0.015 & & & \\ 
	\noalign{\smallskip}\hline \noalign{\smallskip}
    \end{tabular}
    \caption{Measured masses and mass differences of \rmKzeroS, \rmLambda, \rmXi and \rmOmega, accompanied by their statistical and systematic (due to the topological and kinematic selections) uncertainties. Here, these measurements have been performed with a modified Gaussian for the signal and a first order polynomial for the background.}\label{tab:SystTopoKineSelections}
\end{table}

\subsubsection{Influence on the mass difference mass}

In the \tab\ref{tab:SystTopoKineSelections}, the mass difference have been obtained taking the independently measured mass values of the particle and the anti-particle from the above procedure (\Sec\ref{subsubsec:SystTopoMass}), and using \eq\ref{eq:MassDifference}. The uncertainties are then propagated to obtain the statistical and systematic uncertainties on the mass difference. It does not result directly from the aforementioned procedure. In that sense, the mass difference measurement is \textit{indirect}. It carries the full systematic uncertainties from the particle and anti-particle mass values. By extracting the mass difference in a more \textit{direct} way -- similarly to what is done for the mass in \Sec\ref{subsubsec:SystTopoMass} --, part of the uncertainties from the particle and anti-particle masses would cancel out in the difference, resulting in a smaller systematic uncertainty.\\

To that end, an additional step needs to be introduced in the previous strategy in \Sec\ref{subsubsec:SystTopoMass}. For each set of cuts $i$, both particle and anti-particle masses -- $\mu_{i, \textsc{part.}}$ and $\mu_{i, \overline{\textsc{part.}}}$ --  are extracted as well as their uncertainties, $\sigma_{i, \textsc{part.}}$ and $\sigma_{i, \overline{\textsc{part.}}}$. From these, the computation of the mass difference is performed, 
\begin{equation}
\frac{\Delta \mu_{i}}{  \mu_{i} } = 2 \cdot \frac{\mu_{i, \textsc{part.}}-\mu_{i, \overline{\textsc{part.}}}}{\mu_{i, \textsc{part.}}+\mu_{i, \overline{\textsc{part.}}}},
\end{equation}
and the uncertainties are propagated in order to get the one on the mass difference, 
\begin{equation}
\sigma_{\Delta \mu_{i} /\mu_{i} }=  4 \cdot \sqrt{ \left(\frac{-\mu_{i, \overline{\textsc{part.}}}}{\left(\mu_{i, \textsc{part.}} + \mu_{i, \overline{\textsc{part.}}} \right)^{2}}\right)^{2} \sigma_{\mu_{i, \textsc{part.}}}^{2} + \left(\frac{\mu_{i, \textsc{part.}}}{\left(\mu_{i, \textsc{part.}} + \mu_{i, \overline{\textsc{part.}}} \right)^{2}}\right)^{2} \sigma_{\mu_{i, \overline{\textsc{part.}}}}^{2} }.
\end{equation}\\

Similarly to the mass extraction, the mass difference and its uncertainties are calculated from the $\Delta \mu_{i}/  \mu_{i}$ and $\sigma_{\Delta \mu_{i} /\mu_{i} }$ distributions over $N$ different set of cuts:
\begin{itemize}
\item[$\bullet$] the \textit{measured mass difference} corresponds to the mean value of the $\Delta \mu_{i}/  \mu_{i}$ distribution,
\item[$\bullet$] the \textit{systematic uncertainty} due to the candidate selections is the standard deviation of the $\Delta \mu_{i}/  \mu_{i}$ distribution,
\item[$\bullet$] and the \textit{statistical uncertainty} is given by the mean value of the $\sigma_{\Delta \mu_{i} /\mu_{i} }$ distribution.
\end{itemize}

\begin{table}[t]
    \centering
    \begin{tabular}{cccc}
    \noalign{\smallskip}\hline \noalign{\smallskip}
    Particle & Mass difference & \multicolumn{2}{c}{Uncertainty}\\  
    & ($\times 10^{-5}$) & statistical ($\times 10^{-5}$) & systematic ($\times 10^{-5}$) \\
    \noalign{\smallskip}\hline \noalign{\smallskip}
    \multicolumn{4}{l}{\bf \rmLambda} \\
    Indirect & \bf 4.54 &  0.75 & 1.50 \\
    Direct & \bf 4.68 & 0.77 & 0.79 \\ 
    \noalign{\smallskip}\hline \noalign{\smallskip}
    \multicolumn{4}{l}{\bf \rmXi} \\
    Indirect & \bf 4.54 &  0.75 & 1.50 \\
    Direct & \bf 4.68 & 0.77 & 0.79 \\ 
    \noalign{\smallskip}\hline \noalign{\smallskip}
    \multicolumn{4}{l}{\bf \rmOmega} \\
    Indirect & \bf 0.48 & 1.74 & 1.57  \\
    Direct & \bf 0.53 & 1.75 & 1.19   \\
    \noalign{\smallskip}\hline \noalign{\smallskip}
    \end{tabular}
    \caption{Comparison between \textit{direct} and \textit{indirect} mass difference values of \rmXi and \rmOmega baryons, with their respective uncertainties (statistical and systematical). The total uncertainty is obtained by summing quadratically the statistical and systematical uncertainties. Here, both direct and indirect measurements have been performed with a modified Gaussian for the peak and a first order polynomial for the side-bands.}\label{tab:SystMassDifference}
\end{table}

The results on the directly extracted mass difference are presented in \tab\ref{tab:SystMassDifference}. Although the values obtained directly are consistent with the indirect ones, the associated systematic uncertainties are smaller by approximately 48\% for \rmXi and 25\% for \rmOmega. Due to this gain in precision, from now on, the mass difference will always be extracted directly.

\subsection{Stability of the results}
\label{subsec:StabilityResults}

\subsubsection{Dependence on the data taking period}

\subsubsection{Dependence on the decay radius}



\subsubsection{Dependence on the transverse momentum}
\label{subsubsec:MassDependenceOnPt}

Although the invariant mass expression in \eq\ref{eq:CascInvMass} involves only the momentum vector of the decay daughters, it can be re-written to show the \textit{explicit} dependency on the total momentum in \eq\ref{eq:InvMassPtotDependenceCasc},
\begin{align}
M_{\rm candidate}^2( \textrm{casc.}) &= \Big(\sqrt{ \textbf{p}_{\rm V0}^2 + m_{\rmLambda}^2} + \sqrt{ \textbf{p}_{\rm bach.}^2 + m_{\rm bach.}^2}\Big)^2 - ( \textbf{p}_{\rm V0} + \textbf{p}_{\rm bach.})^2 \\
&= \Big(\sqrt{ p_{\rm V0}^2 + m_{\rmLambda}^2} + \sqrt{ p_{\rm bach.}^2 + m_{\rm bach.}^2}\Big)^2 - \left( p_{\rm V0}^{2} + p_{\rm bach.}^{2} + 2 \cdot p_{\rm V0} \cdot p_{\rm bach.} \cos \theta \right),
\label{eq:InvMassPtotDependenceCasc}
\end{align}
and in particular, the \textit{explicit} dependency on the transverse and longitudinal momenta in \eq\ref{eq:InvMassPtPzDependenceCasc},
\begin{equation}
\begin{split}
M_{\rm candidate}^2( \textrm{casc.}) &= \Big(\sqrt{ p_{\rm T, V0}^2 + p_{\rm z, V0}^2 + m_{\rmLambda}^2} + \sqrt{ p_{\rm T, bach.}^2 + p_{\rm z, bach.}^2 + m_{\rm bach.}^2}\Big)^2 \\
&\quad - \big( p_{\rm T, V0}^{2} + p_{\rm T, bach.}^{2} + 2 \cdot p_{\rm T, V0} \cdot p_{\rm T, bach.} \cos \theta_{xy}\\
&\quad + p_{\rm z, V0}^{2} + p_{\rm z, bach.}^{2} + 2 \cdot p_{\rm z, V0} \cdot p_{\rm z, bach.} \cos \theta_{z} \big),
\end{split}
\label{eq:InvMassPtPzDependenceCasc}
\end{equation}
where $\theta$, $\theta_{xy}$ and $\theta_z$ are opening angles, introduced and discussed in more details in the next section \Sec\ref{subsubsec:OpAngleDependence}.



\subsubsection{Dependence on the opening angles}
\label{subsubsec:OpAngleDependence}

As Different opening angles can be considered.

\begin{itemize}
\item \textbf{the opening angle in 3D}, that will simply be called \textit{opening angle} or \textit{3D opening angle} :\\
There are two ways to compute this quantity, depending if the wanted value needs to be signed or unsigned. Here, it has been decided that value of the opening angle would be unsigned. It can be calculated from the momentum vectors of the positive and negative decay daughters :
\begin{align}
&{\bf p_{\rm pos.}} \cdot {\bf p_{\rm neg.}} = p_{\rm pos.} p_{\rm neg.} \cos\left(\theta\right) \\
\Rightarrow \qquad &\theta = \arccos \frac{ \left( {\bf p_{\rm pos.}} \cdot {\bf p_{\rm neg.}} \right) \cdot {\bf n}}{ p_{\rm pos.} \ p_{\rm neg.}}
\label{eq:OpeningAngle3D}
\end{align}
\item \textbf{the transverse opening angle} :\\
Here, the sign of the opening angle in the transverse plane is important, since it relates to cowboy and sailor configurations. A signed angle can be obtained using the cross product between the momentum vectors of the decay daughters :
\begin{align}
&{\bf p_{\rm pos.}} \times {\bf p_{\rm neg.}} = p_{\rm pos.} p_{\rm neg.} \sin\left(\theta\right) \ {\bf n} \\
\Rightarrow \qquad &\theta = \arcsin \frac{ \left( {\bf p_{\rm pos.}} \times {\bf p_{\rm neg.}} \right) \cdot {\bf n}}{ p_{\rm pos.} \ p_{\rm neg.}}
\label{eq:OpeningAngle2D}
\end{align}
The candidate is said to be in sailor configuration if $ B \left( p_{x, \text{pos}} \ p_{y, \text{neg}} - p_{x, \text{neg}} \ p_{y, \text{pos}} \right) > 0$, with B being the magnetic field. Conversely, it is in sailor configuration if $ B \left( p_{x, \text{pos}} \ p_{y, \text{neg}} - p_{x, \text{neg}} \ p_{y, \text{pos}} \right) < 0$

\item \textbf{the longitudinal opening angle } :\\
The opening angle in the longitudinal direction, $\theta_z$ can be deduced directly from the difference of longitudinal angle between the two decay daughters :
\begin{equation}
\theta_{z} = \theta_{z, \bf{pos.}} - \theta_{z, \bf{neg.}}
\label{eq:OpeningAngleZ}
\end{equation}
\end{itemize}

\subsubsection{Dependence on the azimuthal angles}

\subsubsection{Dependence on the rapidity}

\subsubsection{Dependence on the event multiplicity}
\label{subsubsec:EventMultDependence}

The event multiplicity is determined using the VZERO detectors as multiplicity estimator, as described in \Sec\ref{subsubsec:VZERO}. The total charge deposited in each VZERO arrays provides a measurement of the charge particle multiplicity, through the calculation of the average signal amplitude denoted as VZERO-M\footnote{In fact, the VZERO multiplicity estimator corresponds rather to the VZERO-M$/\langle \text{VZERO-M}\rangle$. This normalisation allows to account for the ageing of the scintillator arrays, that become less transparent over time leading to a deterioration of the detector performances.}. 

\begin{table}[t]
    \centering
    \begin{tabular}{c|ccccc}
    \noalign{\smallskip}\hline \noalign{\smallskip}
    Multiplicity Class & \upperRomannumeral{1} & \upperRomannumeral{2} & \upperRomannumeral{3} & \upperRomannumeral{4} & \upperRomannumeral{5} \\
	\sigmaIdx[]/\sigmaIdx[\INELZero] & 0-0.95\% & 0.95-4.7\% & 4.7-9.5\% & 9.5-14\% & 14-19\% \\	        
	$\langle \dNchdeta \rangle$ & $21.3 \pm 0.6$ & $16.5 \pm 0.5$ & $13.5 \pm 0.4$ & $11.5 \pm 0.3$ & $10.1 \pm 0.3$ \\
	\noalign{\smallskip}\hline \noalign{\smallskip}
	Multiplicity Class & \upperRomannumeral{6} & \upperRomannumeral{7} & \upperRomannumeral{8} & \upperRomannumeral{9} & \upperRomannumeral{10} \\
	\sigmaIdx[]/\sigmaIdx[\INELZero] & 19-28\% & 28-38\% & 38-48\% & 48-68\% & 68-100\% \\
	$\langle \dNchdeta \rangle$ & $8.45 \pm 0.25$ & $6.72 \pm 0.21$ & $5.40 \pm 0.17$ & $3.90 \pm 0.14$ & $2.26 \pm 0.12$ \\
	\noalign{\smallskip}\hline \noalign{\smallskip}
    \end{tabular}
    \caption{Event multiplicity classes, with the corresponding fraction of the total inelastic cross section \INELZero (\sigmaIdx[]/\sigmaIdx[\INELZero]) and average charged particle multiplicity at mid-rapidity in pp at \sqrtS = 7 \tev, $\langle \dNchdeta \rangle$. Table taken from \cite{alicecollaborationMultiplicityDependenceLightflavor2019}.}
    \label{tab:MultiplicityClassesCPT}
\end{table}

\subsection{Momentum scale calibration}

The dominant source of systematic uncertainty comes from the momentum scale calibration. This can originate from the uncertainty on the value of the magnetic field (\Sec\ref{subsubsec:ImprecisionMagneticField}) or imperfect energy loss corrections (\Sec\ref{subsubsec:ImperfectEnergyLossCorrections})

\subsubsection{Imprecision on the magnetic field}
\label{subsubsec:ImprecisionMagneticField}

As shown on \fig, the data sample has been collected with two opposite magnetic field polarities, $B = \pm 0.5$ T. In complement to \Sec\ref{subsec:StabilityResults}, the stability of the mass and mass difference measurements is checked by dividing the data sample according to the field configuration. \\


The measurement of the magnetic field in the L3 magnet has been performed in 2007 and is reported in \cite{shahoyanSummaryL3Magnet2007}. It uses 31 Hall probes, calibrated to a precision of 1 Gauss and distributed over two arms, that could rotate around the beam axis and translate along the very same axis. Based on a set of 480 measurement points, the field were interpolated in order to build the full magnetic field map within the L3 volume. Concerning the precision of the latter, the analysis \cite{shahoyanSummaryL3Magnet2007} concludes the following:
\begin{quote}
\textit{ [...] the difference between the corrected data and the obtained parameterization which gives an estimate of the uncertainty for the latter (on top of the mentioned constant transverse field): within the TPC volume the differences are contained in 2 Gauss range although on the periphery of the scanned region there are points with difference reaching 5-6 Gauss (these points constitute less than 1 \% of all data).} 
\end{quote} 

Since the daughter tracks are required to cross at least 70 readout rows in the TPC, likely distributed over different sectors, the contribution of the points located in the periphery of the scanned region (1 \% of all data) can reasonably be considered as negligible. Therefore, for the whole L3 volume, a 2 Gauss uncertainty on the magnetic field is retained.\\

An uncertainty on the magnetic field translates into a shift of the transverse momentum components of the decay daughters. Transverse momentum is related to magnetic field $B_{0}$ and the track curvature $R$ through the relation ${\pT}_{0} = q B_{0} R$. If the magnetic field $B$ is smaller or greater than its nominal value, $B_{0}$, by 2 Gauss, the transverse momentum would respectively be scaled down or up by a factor $B/B_{0}$ :
\begin{equation}
{\pT}_{0} = q B_{0} R \qquad \Rightarrow \qquad \pT = \frac{B}{B_{0}} {\pT}_{0}
\end{equation}

Here is the strategy adopted to evaluate the impact of the magnetic field imprecision : the transverse components of all the decay daughters will be scaled up or down by $B/B_{0}$ -- with $B$ being equal to $B_{0}$ plus or minus 2 Gauss --, the mass will then be extracted as explained in section~\ref{sec:Section04.c-} and the maximum deviation with respect to the mass measured with the nominal value of the magnetic field will be quoted as our uncertainty due to the $B$-field imprecision. The numerical value of the latter can be found in \tab\ref{tab:BFieldPrecision} for \rmKzero, \rmLambda, \rmXi and \rmOmega.

\begin{table}[!h]
    \begin{center}
        \begin{tabular}{l|c|c}       
            \noalign{\smallskip} \hline \noalign{\smallskip}        
            Particle & \multicolumn{2}{c}{Uncertainty on the} \\
            & mass (\mmass) & mass difference ($\times 10^{-5}$) \\
            \noalign{\smallskip}\hline \noalign{\smallskip}
            \rmKzeroS & 0.080 & /\\
            \noalign{\smallskip}\hline \noalign{\smallskip}
            \rmLambda & 0.013 & negligible\\
            \rmAlambda & 0.013 & negligible\\
            \noalign{\smallskip}\hline \noalign{\smallskip}
            \rmXiM & 0.024 & negligible\\
            \rmAxiP & 0.024 & negligible\\
            \noalign{\smallskip}\hline \noalign{\smallskip}
            \rmOmegaM & 0.028 & negligible\\
            \rmAomegaP & 0.028 & negligible\\
            \noalign{\smallskip}\hline \noalign{\smallskip}
        \end{tabular}
        \caption{Systematic uncertainties on the mass (second row) and mass difference (third row) due to the imprecision on the magnetic field value for \rmKzero, \rmLambda, \rmXi and \rmOmega.}
        \label{tab:BFieldPrecision}
    \end{center}
\end{table}

\subsubsection{Energy loss corrections}
\label{subsubsec:ImperfectEnergyLossCorrections}

The uncertainty on the particle's energy losses stem from the calculation of its corrections. The latter arises at two different levels: on one hand, the actual amount of material budget may not be properly accounted for in the detector geometry. In other words, there could be a significant misknowledge on the amount of material budget in the detector. On the other hand, the calculation of the energy loss corrections could be erroneous.

\begin{figure}[t]
%\centering
\hspace*{-1.5cm}
\subfigure[]{
	\includegraphics[width=0.6\textwidth]{Figs/Chapter5/MassVsRadius\_Xi.eps}
	\label{fig:MassVsNbrOfCutSetsXi}
} 
\subfigure[]{
	\includegraphics[width=0.6\textwidth]{Figs/Chapter5/MassVsRadius\_XiMC.eps}
	\label{fig:MassVsNbrOfCutSetsOmega}
} 
\hspace*{-1.5cm}
\subfigure[]{
	\includegraphics[width=0.6\textwidth]{Figs/Chapter5/MassVsRadius\_Omega.eps}
	\label{fig:StatErrVsNbrOfCutSetsXi}
} 
\subfigure[]{
	\includegraphics[width=0.6\textwidth]{Figs/Chapter5/MassVsRadius\_OmegaMC.eps}
	\label{fig:StatErrVsNbrOfCutSetsOmega}
} 
\caption{Measured mass of the \rmXi (top) and \rmOmega baryons (bottom), in the data (left) and in MC (right), as a function of the cascade decay radius. The average radial position for each ITS layer is indicated in dotted line. Note that, for the purpose of the comparison, the MC is \textit{not} re-weighted (\Sec\ref{CorrectionOnTheExtractedMass}).}
	\label{fig:MassVsRadius}
\end{figure}

A hint of the latter is found in \fig\ref{fig:MassVsRadius}. Whatever the particle of interest, the reconstructed mass increases with the transverse momentum and the decay radius, in the data and MC. It turns out that this trend results from several approximations in the implementation of the energy loss corrections in the ALICE framework. There are three, that can be classified from the most to the \say{least} significant.

\begin{enumerate}
\item As explained in \Sec\ref{subsubsec:TrackReco}, in the final stage of the tracking, all tracks are propagated inwards to their DCA to the primary vertex, taking into account stochastic processes such as energy losses. While this makes sense for primary tracks, it introduces a bias for secondary ones. Being a decay product, the inward propagation of a secondary track should stop at the decay point, where its parameters are related to the mother particle. Instead, at each propagation step between the secondary and primary vertices, the track receives additional energy from \dEdx-corrections (footnote \ref{footnote:EnergyLoss}). This excess of energy builds up with the decay point position, biasing further the track parameters the further away the secondary vertex is. Nevertheless, at this stage of the event reconstruction, there is no way to distinguish a primary from a secondary particle\footnote{Concerning V0 decays, there is indeed no way to identify a secondary particle at this stage of the reconstruction using the so-called \textit{offline} reconstruction, presented \chap\ref{chap:V0CascReconstruction}. However, there exists another approach, dubbed \textit{on-the-fly}, that performs that track finding, track fitting and V0 vertexing simultaneously. Although it has been checked that on-the-fly V0s do not exhibit the mass dependence on the transverse momentum and radial position of the decay point, they can not be used in the analysis as there exists no on-the-fly cascades.}. For that reason, this bias is expected to be removed later, during the V0 and cascade reconstruction. However, as mentioned in \Sec\ref{subsubsec:V0Formation} (footnote \ref{footnote:EnergyLossV0CascVertexing}), the propagation of daughter tracks from the DCA to the primary vertex to the V0/cascade decay point is performed with no energy loss corrections. This means that the energy previously added during the final inward propagation of the tracking between the secondary and primary vertices, has not been subtracted, leading to additional energy/momentum in the track parameters at the
secondary decay position and thus to an offset in the invariant mass.

\item The energy loss calculation relies on the same parametrisation of the Bethe-Bloch formula (\eq\ref{eq:BetheBloch}) as \GeantThree and \GeantFour\footnote{Although \GeantThree and \GeantFour are two different version of \textsc{Geant} software series, their treatement of the energy losses of a charged particle in a medium remains the same.}. For the parameters related to material, they are using the database in \cite{geant4Geant4MaterialDatabase}. However, as explained in \Sec\ref{subsubsec:TrackReco}, the particle energy losses are calculated and corrected assuming that all the materials are made of Si in the ITS volume (including the beam pipe) and Ne in the TPC. This approximation leads inevitably to a systematic misevaluation of the actual energy losses, and thus to bias in the invariant mass.

\item Along the same line, the Bethe-Bloch formula in \eq\ref{eq:BetheBloch} also depends on the particle traversing the material and, in particular, its charge, momentum and mass. While the Kalman filter provides the first two, the last one comes from the measurement of the energy deposit in the TPC volume, which offers a preliminary particle identification. There is no guarantee, though, that the latter coincides with the expected mass hypothesis  for a \rmKzeroS, \rmLambdaPM, \rmXiPM or \rmOmegaPM decay. For instance, \Sec\ref{subsubsec:TrackReco} explains that the pion mass is taken as default value. As a matter of fact, only a fraction of the candidates has the correct mass hypothesis for both decay daughters as shown in \fig\ref{fig:FractionOfPIDForTracking}. If the mass hypothesis used in the energy loss calculation turns out to be incorrect, the wrong amount of energy loss correction are applied.

\end{enumerate}

\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{Figs/Chapter5/FractionOfPIDForTracking.eps}
	\caption{Pictural representation of the fix on the energy loss corrections applied on the proton daughter of a \rmLambdaPM.}
	\label{fig:FractionOfPIDForTracking}
\end{figure}


There are different ways to address these issues. The approach followed in this analysis consists in i) replaying the track propagation in order to remove the previous energy loss corrections, and ii) re-applying them with the correct mass hypothesis, appropriate material parameters and stopping at the secondary decay position. The \fig\ref{fig:SchemeRetroCorrection} gives a description of this procedure, also called \textit{retro-corrections}.

\begin{figure}[t]
	\centering
	\includegraphics[width=1\textwidth]{Figs/Chapter5/Schema-RetroCorrections.eps}
	\caption{Pictural representation of the fix on the energy loss corrections applied on the proton daughter of a \rmLambdaPM. The general idea breaks off in two stages: removing the previous \dEdx-corrections below the TPC inner wall (1. and 2.), and re-applying them appropriately (3.). The first stage starts with the propagation of the track parameters, initially at the decay position, to its DCA to the primary vertex without accounting for energy loss (1.). Then, the track is propagated to the TPC inner wall (2.) as performed during the final stage of the tracking (\Sec\ref{subsubsec:TrackReco}). In the second stage, the energy loss corrections are re-applied with the correct mass hypothesis -- here, the proton mass -- and stopping at the secondary vertex position (3.). Modified version of the figure from \cite{maireTrackReconstructionPrinciple2011}.}
	\label{fig:SchemeRetroCorrection}
\end{figure}

The procedure starts off with the track parameters at the V0/cascade decay point. They are extrapolated to its point of closest approach to the primary vertex, without accounting for energy losses (\fig\ref{fig:SchemeRetroCorrection}, 1.). This boils down to undo the track propagation in \Sec\ref{subsubsec:V0Formation} and recover the track parameters as they were before the V0/cascade reconstruction. From this point, the track is propagated to its position at the TPC inner wall, in the exactly same condition as in the final stage of the tracking (\Sec\ref{subsubsec:TrackReco}): same mass hypothesis, same consideration on the detector material. This means that, at each step, the track looses the identical amount of energy which was previously added. At the TPC inner wall, the aforementioned energy loss corrections \textit{in the ITS} have been fully removed (\fig\ref{fig:SchemeRetroCorrection}, 2.). As most of the material budget comes from the ITS, the wrong energy loss corrections in the TPC can be ignored in first approximation. This last point was later verified with a propagation up to the TPC outer wall; no significant change could have been observed.  

The second stage takes over with the re-application of the energy loss corrections. From the TPC inner wall, the track parameters are propagated to the secondary vertex position with the appropriate mass hypothesis and the adequate material, in order to correct the right amount of energy losses this time (\fig\ref{fig:SchemeRetroCorrection}, 3.).

The \fig shows the application of this procedure in the data and MC.\\

Another source of systematic effect related to the energy loss corrections comes from the limited knowledge on the material budget in the detector. If there is a discrepancy between the amount of \textit{known} crossed material and the actual one, the estimation of the energy loss will be directly impacted. 

The material budget of the ALICE detector has been estimated experimentally by reconstructing pairs of electron-position originating from photons converted in the detectors. The photon conversion probability being sensitive to the geometry, the composition of detector or the material budget, it provides a precise description of the material distribution. In the LHC Run-2, the material budget in the central barrel of the ALICE detector is known with a precision of about 4.5\% \cite{alicecollaborationPerformanceALICEExperiment2014}\cite{alicecollaborationValidationALICEMaterial2022}\footnote{As a matter of fact, at the time of the writing of this manuscript, another photon conversion analysis \cite{alicecollaborationDatadrivenPrecisionDetermination2023} has been performed, that quotes an uncertainty on the material budget of 2.5\%. However, not only the precision has changed, but also the amount of material budget. However, as of 2023, there have been no re-processing of the data nor production of MC simulations using this updated version of the material distribution. For that reason, the latter will not be used in this work.}. 


By varying the material budget, the impact of the misknowledge on the actual material budget can be estimated. This kind of investigation is typically carried out on simulated data. The idea consists in running two simulations: one with an increased/decreased material density\footnote{There could be two ways to increase/decrease the material budget. One could increase the thickness of the detectors, but this option is rather disfavoured since it may introduce clipping, overlapping of detector volumes. An alternative is to vary the material density, such as changing the Si density by $\pm$ 4.5\%. This offers the same results as the first possibility without affecting the detector geometry.}, and another with the nominal one. In both cases, the event reconstruction uses the standard detector geometry, \ie with the standard amount of material budget. The comparison of the results from these two simulations allows to determine the systematic effect due to an uncertainty of 4.5\% on the material budget.

In an ideal scenario, this study should rely on three MC productions: one with nominal material density serving as reference, another with a 4.5\% increase of the density with respect to the standard value, and a last one with a decrease by the same amount. In this way, the effect of a increase or decrease of the material budget can be fully assessed. 

It turns out that there are no such MC productions in pp collisions at \sqrtS = 13 \tev. Instead, there exist only simulations with material budget increased 30\%. Here, the approach is slightly different: the goal is to change excessively the material density to guarantee the observation of a systematic effect. The latter is then scaled down to the actual precision on the material budget. In other words, by estimating the variation of the results induced by a 30\% increase of the material budget and by assuming linearity, the effect of increase of 4.5\% of the material density can derived. It is given by:
\begin{equation}
\begin{bmatrix}
\textsc{\footnotesize Variation of the results due to}\\
\textsc{\footnotesize 4.5\% extra material budget}
\end{bmatrix}
= \frac{4.5\%}{30\%} \times
\begin{bmatrix}
\textsc{\footnotesize Variation of the results due to}\\
\textsc{\footnotesize 30\% extra material budget}
\end{bmatrix}
\end{equation}

However, there exist simulations with an increase/decrease of the material density by 4.5\%, but in Pb-Pb collisions at \sqrtSnn = 5.02 \tev. Consequently, the results of this study are cross-checked with those obtained using these MC productions.

\subsection{Mass extraction}

The elements related to the mass extraction are also included in the present study. It covers the considered fit functions for modeling the peak and the background, the fitting range and the bin width of the invariant mass distribution.

\subsubsection{Choice of the fit function}

By exploiting different peak and background functions for the mass extraction, one can estimate the systematic effect due to the choice of model. The considered functions for each particle have been explained and detailed in \Sec\ref{subsubsec:SignalBackShape}. In total, four combinations of peak and background models are tested, for which the masses and mass differences, as well as their statistical and systematic uncertainties, are measured using the procedure presented in \Sec\ref{subsec:SystTopoAndTrackSelections}. 

\subsubsection{Choice of the fitting range}
\label{subsubsec:SystFittingRange}

In order to study the effect that element of the fit, masses and mass differences have been measured for 20 000 randomly generated fitting range and fixing the cascade candidate selections to their values in Tab. 3. The randomization is performed on both edges of the adjustement range, according to an uniform distribution on the intervals presented in Tab. 13. The standard deviation over the the whole set of fitting range provides the uncertainty due to the choice of the adjustement interval.

The results are presented in the two last columns of \tab\ref{tab:SystFittingRange}. The order of magnitude of the uncertainties due to the choice of the fitting range on the mass difference of \rmXi and \rmOmega were about $10^{-7}-10^{-8}$ ; to be conservative, we will quote an error of $10^{-7}$ on their mass difference values.

\begin{table}[h]
    \centering
    \begin{tabular}{ccc|cc}
    \noalign{\smallskip}\hline \hline \noalign{\smallskip}
    Particle & \multicolumn{2}{c}{Randomization interval (\mmass) }  & \multicolumn{2}{c}{Uncertainty on the ...}  \\
    & Bottom edge & Top edge & ...mass (\mmass) & ...mass difference $(\times 10^{-5})$\\
    \noalign{\smallskip}\hline \hline \noalign{\smallskip}
    \rmKzero & \bf $\left[ 0.460\ ; \ 0.475 \right]$ & \bf $\left[ 0.520\ ; \ 0.540 \right]$ & 0.002 & / \\
    \noalign{\smallskip}\hline \noalign{\smallskip}
    \rmLambda & \bf $\left[ 1.098\ ; \ 1.108 \right]$ & \bf $\left[ 1.125\ ; \ 1.135 \right]$ & 0.001 & 0.02 \\
    \noalign{\smallskip}\hline \noalign{\smallskip}
    \rmXi & \bf $\left[ 1.265\ ; \ 1.3 \right]$ & \bf $\left[ 1.345\ ; \ 1.38 \right]$ & 0.001 & 0.01 \\
    \noalign{\smallskip}\hline \noalign{\smallskip}
    \rmOmega & \bf $\left[ 1.615\ ; \ 1.65 \right]$ & \bf $\left[ 1.695\ ; \ 1.73 \right]$ &  0.001 & 0.02 \\
    \noalign{\smallskip}\hline \hline \noalign{\smallskip}
    \end{tabular}
    \caption{Randomization intervals on the bottom and top edges of the fitting range for \rmKzero, \rmLambda, \rmXi and \rmOmega. The adjustement ranges are generated according to an uniform law. The uncertainties due to the choice of the fitting range are indicated in the two last columns.}\label{tab:SystFittingRange}
\end{table}

\subsubsection{Choice of the binning}

Similarly to the choice of the fitting range (\Sec\ref{subsubsec:SystFittingRange}), the binning of the invariant mass distributions may influence the output of the fit. By default, the binning is set at 0.5 \mmass. To evaluate its impact, the binning has been varied from 1 to 0.25 \mmass with a step of 0.25 \mmass. The standard deviation of the measurements performed using the different binning provides the systematic uncertainty due to the granularity of the invariant mass distributions.

The results are presented in. This element of the analysis introduces an uncertainty of
0.001 \mmass on the mass values, and 0.02, 0.06 and 0.13 $\times 10^{-5}$ on the mass difference values of \rmLambda, \rmXi and \rmOmega respectively.

\subsection{Pile-up treatment}

A contribution to the systematic uncertainty can also originate from the pile-up rejection introduced in \Sec\ref{subsec:V0CascSelections}. It is evaluated by varying the rejection requirements. 

Pile-up events may induce a bias in the mass measurement due to the association of tracks coming from different collisions, which possibly lead to the formation of a V0 or cascade candidate. Considering the tight selections applied on the candidate variables -- and most particularly, on the cosine of the pointing angle to the primary vertex (\tabs\ref{tab:V0Selections} and \ref{tab:CascadeSelections}) --, the probablity of such misassociation is expected to be relatively low. Therefore, the measurement is performed with and without the pile-up rejection cut. If the effect turns out to be statistically significant, the absolute deviation with respect to the standard configuration is taken as systematic uncertainty.

\subsection{Correction on the extracted mass}

\subsection{Precision on the tabulated masses}

The V0 and cascade masses are extracted from their invariant mass distribution, as explained in \Sec\ref{subsec:MassExtraction}. The \eq\ref{eq:LambdaInvMass} and \ref{eq:CascInvMass} highlight the quantities entering into the invariant mass calculation of a candidate, \ie the mass and momenta of each daughter particle. In particular, even for the \rmLambdaPM daughter of \rmXiPM or \rmOmegaPM decay, the former always corresponds to the tabulated mass in the PDG. As presented in \tab\ref{tab:PDGmass}, the latter has a finite precision. Although the PDG mass values of proton and pion are determined with a high degree of precision (\sigmaPDG < 1 \kmass), this is not the case of the \rmKPM and \rmLambdaPM (\sigmaPDG $\sim$\orderOf{10} \kmass). Consequently, they can possibly induce the systematic bias in the invariant mass calculation; all the more so for the cascades, since the latter is one of the products of the \rmXi decay, and both the former and the latter are the two decay daughters of the \rmOmega. 

\begin{table}[t]
    \begin{center}
        \begin{tabular}{lcccc}       
            \noalign{\smallskip}\hline \noalign{\smallskip}        
            Particle & \rmPiPM & \Kplusmin & \pOrPbar & \rmLambdaPM \\
            \noalign{\smallskip}\hline \noalign{\smallskip}
			\mPDG (\mmass) & 139.57039 & 497.677 & 938.27208816 & 1115.683 \\
            \sigmaPDG (\mmass) & 0.00018 & 0.016 & 0.00000029 & 0.006 \\ 
            \noalign{\smallskip}\hline \noalign{\smallskip}
        \end{tabular}
        \caption{Particle mass (\mPDG) as well as its uncertainty (\sigmaPDG) for the decay daughters of \rmKzeroS, \rmLambda, \rmXi and \rmOmega, listed into \cite{particledatagroupReviewParticlePhysics2022}, as of 2023.}
        \label{tab:PDGmass}
    \end{center}
\end{table}

Similarly as in \Sec\ref{subsec:SystTopoAndTrackSelections}, the mass of each decay daughter is varied randomly 20 000 times, according to a Gaussian distribution centred on the PDG value and with the associated uncertainty \sigmaPDG as standard deviation. In case, a systematic effect is observed, the standard deviation of the results over the whole set of generated particle masses is taken as systematic uncertainty.


\section{Results}